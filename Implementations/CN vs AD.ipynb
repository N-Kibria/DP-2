{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10720773,"sourceType":"datasetVersion","datasetId":6645569}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-13T07:15:03.653783Z","iopub.execute_input":"2025-10-13T07:15:03.654316Z","iopub.status.idle":"2025-10-13T07:15:08.984556Z","shell.execute_reply.started":"2025-10-13T07:15:03.654294Z","shell.execute_reply":"2025-10-13T07:15:08.983839Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting imbalanced-learn==0.10.1\n  Downloading imbalanced_learn-0.10.1-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nDownloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: imbalanced-learn\n  Attempting uninstall: imbalanced-learn\n    Found existing installation: imbalanced-learn 0.13.0\n    Uninstalling imbalanced-learn-0.13.0:\n      Successfully uninstalled imbalanced-learn-0.13.0\nSuccessfully installed imbalanced-learn-0.10.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nimportant\nDTCA-Net: Dual-Transformer Cross Attention Network\nComplete pipeline for AD/FTD detection from EEG signals\nFIXED VERSION - Ready for full dataset\n\"\"\"\n\nimport os\nimport re\nimport glob\nimport random\nimport math\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nfrom typing import Tuple, List\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport mne\nimport pywt\nfrom scipy.signal import hilbert\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, precision_score, \n    recall_score, roc_auc_score, roc_curve\n)\nfrom sklearn.utils import check_random_state\nfrom imblearn.over_sampling import SMOTE\n\nimport numba as nb\n\n# ═══════════════════════════════════════════════════════════════════════════\n# CONFIGURATION\n# ═══════════════════════════════════════════════════════════════════════════\n\n# Paths\nDATA_DIR = \"/kaggle/input/openneuro-ds004504/ds004504/derivatives\"\nFEATURES_DIR = \"./features\"\nRESULTS_DIR = \"./results\"\n\n# Create directories\nos.makedirs(FEATURES_DIR, exist_ok=True)\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# DWT Configuration\nMAX_LVL = 8\nWAVELET = 'db4'\nband2levels = {\n    'delta': [1, 2, 3],\n    'theta': [4],\n    'alpha': [5],\n    'beta': [6],\n    'gamma': [7]\n}\nband_list = list(band2levels.keys())\n\n# Window Configuration - FIXED TO MATCH\nMINUTE_LEN = 60\nSFREQ = 256\nMINUTE_SAMPLES = int(MINUTE_LEN * SFREQ)  # 15360 samples per minute\nN_SUBWINS_PER_MINUTE = 11  # Fixed number of sub-windows per minute\n\n# Model Configuration\nSELECTED_CHANNELS = ['O1', 'O2', 'T4', 'T5', 'F7', 'F8']\nBATCH_SIZE = 32\nN_SPLITS = 10\nN_REPETITIONS = 10\nNUM_EPOCHS = 100\nLEARNING_RATE = 0.0001\n\n# ═══════════════════════════════════════════════════════════════════════════\n# UTILITY FUNCTIONS\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef set_seed(seed: int):\n    \"\"\"Set random seed for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    _ = check_random_state(seed)\n    print(f\"Seed set to: {seed}\")\n\ndef get_subject_id(filepath: str) -> int:\n    \"\"\"Extract subject ID from filepath.\"\"\"\n    for part in filepath.split(os.sep):\n        if part.startswith('sub-'):\n            return int(part.replace('sub-', '').strip())\n    return None\n\n# ═══════════════════════════════════════════════════════════════════════════\n# FEATURE EXTRACTION: PTE\n# ═══════════════════════════════════════════════════════════════════════════\n\n@nb.njit(fastmath=True, cache=True)\ndef _entropy(counts, length):\n    \"\"\"Calculate entropy.\"\"\"\n    H = 0.0\n    for c in counts:\n        if c > 0:\n            p = c / length\n            H -= p * np.log2(p)\n    return H\n\n@nb.njit(fastmath=True, cache=True)\ndef compute_PTE_numba(phase, delay):\n    \"\"\"Compute Phase Transfer Entropy using Numba JIT.\"\"\"\n    m, n = phase.shape\n    raw = np.zeros((m, m), np.float64)\n    L = n - delay\n    \n    for i in range(m):\n        x = phase[i, :L]\n        for j in range(m):\n            y = phase[j, :L]\n            ypr = phase[j, delay:]\n            vmax = int(max(x.max(), y.max(), ypr.max()) + 1)\n            \n            cnt_y = np.bincount(y, minlength=vmax)\n            idx_ypr_y = ypr + vmax * y\n            cnt_ypr_y = np.bincount(idx_ypr_y, minlength=vmax * vmax)\n            idx_y_x = y + vmax * x\n            cnt_y_x = np.bincount(idx_y_x, minlength=vmax * vmax)\n            idx_3d = ypr + vmax * (y + vmax * x)\n            cnt_3d = np.bincount(idx_3d, minlength=vmax * vmax * vmax)\n            \n            Hy = _entropy(cnt_y, L)\n            Hypr = _entropy(cnt_ypr_y, L)\n            Hyx = _entropy(cnt_y_x, L)\n            Hyprx = _entropy(cnt_3d, L)\n            \n            raw[i, j] = Hypr + Hyx - Hy - Hyprx\n    \n    return raw\n\n@nb.njit(fastmath=True, cache=True)\ndef dPTE_from_raw(raw):\n    \"\"\"Compute directed PTE from raw PTE.\"\"\"\n    sym = raw + raw.T\n    return np.triu(raw / sym, 1) + np.tril((raw / sym).T, -1)\n\ndef reconstruct_band_dwt(data: np.ndarray, levels: List[int]) -> np.ndarray:\n    \"\"\"Reconstruct signal from specific DWT levels.\"\"\"\n    coeffs = pywt.wavedec(data, WAVELET, axis=1, level=MAX_LVL)\n    kept = [np.zeros_like(c) for c in coeffs]\n    for lv in levels:\n        kept[lv] = coeffs[lv]\n    return pywt.waverec(kept, WAVELET, axis=1)\n\ndef get_delay(phase: np.ndarray) -> int:\n    \"\"\"Estimate optimal delay for PTE.\"\"\"\n    m, n = phase.shape\n    c1 = m * n\n    c2 = (phase * np.roll(phase, 1, axis=1) < 0).sum()\n    return int(round(c1 / c2))\n\ndef get_binsize(phase: np.ndarray, c: float = 3.49) -> float:\n    \"\"\"Calculate bin size for phase discretization.\"\"\"\n    m, n = phase.shape\n    return c * np.mean(np.std(phase, axis=1, ddof=1)) * n ** (-1 / 3)\n\ndef discretize_phase(phase: np.ndarray, binsz: float) -> np.ndarray:\n    \"\"\"Discretize phase values.\"\"\"\n    return np.ceil(phase / binsz).astype(np.int32)\n\ndef process_pte_subject(filepath: str, label: str):\n    \"\"\"Process one subject for PTE feature extraction.\"\"\"\n    print(f\"Processing PTE: {filepath}\")\n    raw = mne.io.read_raw_eeglab(filepath, preload=True, verbose='ERROR')\n    raw.resample(SFREQ)\n    \n    data_full = raw.get_data()\n    n_ch = data_full.shape[0]\n    total_samples = data_full.shape[1]\n    \n    n_minutes = total_samples // MINUTE_SAMPLES\n    n_bands = len(band_list)\n    subwin_samples = MINUTE_SAMPLES // N_SUBWINS_PER_MINUTE\n    \n    # Shape: (n_minutes, n_subwins, n_bands, n_ch, n_ch)\n    dp_subject = np.zeros((n_minutes, N_SUBWINS_PER_MINUTE, n_bands, n_ch, n_ch), dtype=np.float64)\n    \n    for mi in range(n_minutes):\n        seg60 = data_full[:, mi * MINUTE_SAMPLES:(mi + 1) * MINUTE_SAMPLES]\n        \n        for bi, band in enumerate(band_list):\n            levels = band2levels[band]\n            band_data = reconstruct_band_dwt(seg60, levels)\n            phase = np.angle(hilbert(band_data, axis=1))\n            delay = get_delay(phase)\n            binsz = get_binsize(phase)\n            dph = discretize_phase(phase + np.pi, binsz)\n            \n            for wi in range(N_SUBWINS_PER_MINUTE):\n                start = wi * subwin_samples\n                end = start + subwin_samples\n                blk = dph[:, start:end]\n                rawP = compute_PTE_numba(blk, delay)\n                dp = dPTE_from_raw(rawP)\n                dp_subject[mi, wi, bi, :, :] = dp\n    \n    subj_id = get_subject_id(filepath)\n    return subj_id, dp_subject, label\n\n# ═══════════════════════════════════════════════════════════════════════════\n# FEATURE EXTRACTION: DIFFERENTIAL ENTROPY\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef compute_DE(signal: np.ndarray) -> float:\n    \"\"\"Compute differential entropy.\"\"\"\n    var = np.var(signal, ddof=1)\n    if var <= 0:\n        return 0.0\n    return 0.5 * math.log(2 * math.pi * math.e * var)\n\ndef process_de_subject(filepath: str, label: str):\n    \"\"\"Process one subject for DE feature extraction - FIXED TO MATCH PTE.\"\"\"\n    print(f\"Processing DE: {filepath}\")\n    \n    raw = mne.io.read_raw_eeglab(filepath, preload=True, verbose='ERROR')\n    raw.resample(SFREQ)\n    \n    data = raw.get_data() * 1e6\n    n_ch = data.shape[0]\n    n_samp = data.shape[1]\n    \n    n_minutes = n_samp // MINUTE_SAMPLES\n    subwin_samples = MINUTE_SAMPLES // N_SUBWINS_PER_MINUTE\n    \n    # Shape: (n_minutes * n_subwins, n_ch, n_bands)\n    total_windows = n_minutes * N_SUBWINS_PER_MINUTE\n    DE_values = np.zeros((total_windows, n_ch, len(band_list)), dtype=float)\n    \n    win_idx = 0\n    for mi in range(n_minutes):\n        seg60 = data[:, mi * MINUTE_SAMPLES:(mi + 1) * MINUTE_SAMPLES]\n        \n        # Extract band signals for the entire minute\n        band_sigs = {\n            band: reconstruct_band_dwt(seg60, band2levels[band])\n            for band in band_list\n        }\n        \n        # Divide into sub-windows\n        for wi in range(N_SUBWINS_PER_MINUTE):\n            start = wi * subwin_samples\n            end = start + subwin_samples\n            \n            for bi, band in enumerate(band_list):\n                sig_window = band_sigs[band][:, start:end]\n                for ch in range(n_ch):\n                    DE_values[win_idx, ch, bi] = compute_DE(sig_window[ch])\n            \n            win_idx += 1\n    \n    subj_id = get_subject_id(filepath)\n    return subj_id, DE_values, label\n\n# ═══════════════════════════════════════════════════════════════════════════\n# DATA LOADING\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef load_data_stratified_kfold(\n    pte_directory: str,\n    DE_directory: str,\n    batch_size: int,\n    selected_classes=(\"alz\", \"ctrl\"),\n    selected_channels=None,\n    n_splits: int = 10,\n    n_repetitions: int = 5,\n):\n    \"\"\"Load and prepare data with stratified k-fold cross-validation.\"\"\"\n    ch_names = [\n        \"Fp1\", \"Fp2\", \"F3\", \"F4\", \"C3\", \"C4\", \"P3\", \"P4\", \"O1\", \"O2\",\n        \"F7\", \"F8\", \"T3\", \"T4\", \"T5\", \"T6\", \"Fz\", \"Cz\", \"Pz\",\n    ]\n    \n    if selected_channels is None:\n        selected_channels = ch_names\n    \n    sel_idx = [ch_names.index(ch) for ch in selected_channels]\n    label_map = {c: i for i, c in enumerate(selected_classes)}\n    \n    def parse_info(fname):\n        m = re.match(r\"sub-(\\d+)_.*_(\\w+)\\.npz\", fname)\n        if not m:\n            return None\n        sid, lbl = int(m.group(1)), m.group(2).lower()\n        if lbl not in selected_classes:\n            return None\n        return sid, lbl\n    \n    def collect_files(directory, file_type='PTE'):\n        \"\"\"Collect files of specific type (PTE or DE).\"\"\"\n        all_files = sorted(\n            [f for f in os.listdir(directory) if f.endswith(\".npz\") and f\"_{file_type}_\" in f],\n            key=lambda f: int(re.search(r\"sub-(\\d+)_\", f).group(1)),\n        )\n        info = [parse_info(f) + (f,) for f in all_files if parse_info(f) is not None]\n        \n        # Drop first 5 subjects from each class\n        drop_ids = {}\n        for cls in selected_classes:\n            ids = sorted({sid for sid, lbl, _ in info if lbl == cls})\n            drop_ids[cls] = set(ids[:5])\n        \n        return [\n            fname\n            for sid, lbl, fname in info\n            if sid not in drop_ids[lbl]\n        ]\n    \n    pte_files = collect_files(pte_directory, file_type='PTE')\n    psd_files = collect_files(DE_directory, file_type='DE')\n    \n    pte_list, psd_list, labels_list, pid_list = [], [], [], []\n    \n    for fname in pte_files:\n        sid, lbl = parse_info(fname)\n        lbl_int = label_map[lbl]\n        arr = np.load(Path(pte_directory) / fname, allow_pickle=True)\n        \n        pte = arr[\"pte_data\"]\n        # Reshape from (n_minutes, 11, 5, 19, 19) to (n_minutes*11, 5, 19, 19)\n        n_minutes = pte.shape[0]\n        pte = pte.reshape(n_minutes * N_SUBWINS_PER_MINUTE, *pte.shape[2:])\n        # Select channels\n        pte = pte[:, :, sel_idx, :][:, :, :, sel_idx]\n        \n        N = pte.shape[0]\n        pte_list.append(pte)\n        labels_list.append(np.full(N, lbl_int, dtype=int))\n        pid_list.extend([sid] * N)\n    \n    for fname in psd_files:\n        sid, _ = parse_info(fname)\n        arr = np.load(Path(DE_directory) / fname, allow_pickle=True)\n        \n        psd = arr[\"DE_features\"]\n        psd = psd[:, sel_idx, :]\n        \n        psd_list.append(psd)\n    \n    X_pte = np.concatenate(pte_list, axis=0)\n    X_psd = np.concatenate(psd_list, axis=0)\n    y = np.concatenate(labels_list, axis=0)\n    pid = np.asarray(pid_list, dtype=int)\n    \n    print(f\"Data shapes - PTE: {X_pte.shape}, DE: {X_psd.shape}, Labels: {y.shape}\")\n    assert X_pte.shape[0] == X_psd.shape[0] == y.shape[0] == pid.shape[0], \\\n        f\"Shape mismatch! PTE: {X_pte.shape[0]}, DE: {X_psd.shape[0]}, Labels: {y.shape[0]}, PID: {pid.shape[0]}\"\n    \n    unique_pids = np.unique(pid)\n    subj_labels = np.array(\n        [Counter(y[pid == sid]).most_common(1)[0][0] for sid in unique_pids]\n    )\n    \n    all_reps = []\n    for rep in range(n_repetitions):\n        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rep)\n        rep_folds = []\n        \n        for subj_tr_idx, subj_va_idx in skf.split(unique_pids, subj_labels):\n            train_pids = unique_pids[subj_tr_idx]\n            val_pids = unique_pids[subj_va_idx]\n            \n            tr_mask = np.isin(pid, train_pids)\n            va_mask = np.isin(pid, val_pids)\n            \n            Xp_tr, Xp_va = X_pte[tr_mask], X_pte[va_mask]\n            Xs_tr, Xs_va = X_psd[tr_mask], X_psd[va_mask]\n            y_tr, y_va = y[tr_mask], y[va_mask]\n            pid_tr, pid_va = pid[tr_mask], pid[va_mask]\n            \n            flat_pte_tr = Xp_tr.reshape(len(y_tr), -1)\n            flat_psd_tr = Xs_tr.reshape(len(y_tr), -1)\n            X_train_flat = np.hstack([flat_pte_tr, flat_psd_tr])\n            \n            sm = SMOTE(random_state=rep)\n            X_bal, y_bal = sm.fit_resample(X_train_flat, y_tr)\n            \n            if hasattr(sm, \"sample_indices_\"):\n                res_idx = sm.sample_indices_\n            elif hasattr(sm, \"_sample_indices\"):\n                res_idx = sm._sample_indices\n            else:\n                idx = np.arange(len(y_tr)).reshape(-1, 1)\n                idx_bal, _ = SMOTE(random_state=rep).fit_resample(idx, y_tr)\n                res_idx = idx_bal.ravel()\n            \n            pid_bal = pid_tr[res_idx]\n            \n            split_at = flat_pte_tr.shape[1]\n            flat_pte_bal = X_bal[:, :split_at]\n            flat_psd_bal = X_bal[:, split_at:]\n            \n            scaler_pte = MinMaxScaler()\n            scaler_psd = MinMaxScaler()\n            \n            flat_pte_bal = scaler_pte.fit_transform(flat_pte_bal)\n            flat_pte_val = scaler_pte.transform(Xp_va.reshape(len(y_va), -1))\n            \n            flat_psd_bal = scaler_psd.fit_transform(flat_psd_bal)\n            flat_psd_val = scaler_psd.transform(Xs_va.reshape(len(y_va), -1))\n            \n            Xp_tr_bal = flat_pte_bal.reshape(-1, *Xp_tr.shape[1:])\n            Xs_tr_bal = flat_psd_bal.reshape(-1, *Xs_tr.shape[1:])\n            Xp_va = flat_pte_val.reshape(Xp_va.shape)\n            Xs_va = flat_psd_val.reshape(Xs_va.shape)\n            \n            def make_loader(x1, x2, y_, p_, shuffle):\n                t1 = torch.from_numpy(x1).float()\n                t2 = torch.from_numpy(x2).float()\n                ty = torch.from_numpy(y_).long()\n                tp = torch.from_numpy(p_).long()\n                ds = TensorDataset(t1, t2, ty, tp)\n                return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n            \n            train_loader = make_loader(Xp_tr_bal, Xs_tr_bal, y_bal, pid_bal, shuffle=True)\n            val_loader = make_loader(Xp_va, Xs_va, y_va, pid_va, shuffle=False)\n            \n            rep_folds.append((train_loader, val_loader))\n        \n        all_reps.append(rep_folds)\n    \n    return all_reps\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MODEL ARCHITECTURE\n# ═══════════════════════════════════════════════════════════════════════════\n\nclass MultiHeadCrossAttention(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super(MultiHeadCrossAttention, self).__init__()\n        self.multihead_attn = nn.MultiheadAttention(\n            embed_dim=d_model, \n            num_heads=num_heads, \n            dropout=dropout, \n            batch_first=True\n        )\n        self.layer_norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n        attn_output, attn_weights = self.multihead_attn(\n            query, key, value, \n            attn_mask=attn_mask, \n            key_padding_mask=key_padding_mask\n        )\n        attn_output = self.dropout(attn_output)\n        output = self.layer_norm(query + attn_output)\n        return output, attn_weights\n\nclass PteTransformer(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n        super(PteTransformer, self).__init__()\n        # PTE input: (batch, 5_bands, 6_channels, 6_channels) = (batch, 5, 6, 6)\n        # Flatten to: (batch, 5, 36) - treat bands as sequence\n        self.flatten_spatial = nn.Flatten(start_dim=2)  # Flatten spatial dimensions\n        spatial_dim = 36  # 6 * 6\n        \n        self.position_encoding = nn.Parameter(torch.randn(1, 5, spatial_dim), requires_grad=True)\n        \n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=spatial_dim,\n            nhead=num_heads,\n            dim_feedforward=hidden_dim,\n            dropout=dropout,\n            batch_first=True,\n            activation=\"gelu\"\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n        self.output_layer = nn.Linear(spatial_dim, output_dim)\n    \n    def forward(self, x):\n        # x: (batch, 5, 6, 6)\n        b = x.shape[0]\n        x = self.flatten_spatial(x)  # (batch, 5, 36)\n        x = self.position_encoding + x\n        x = self.transformer(x)  # (batch, 5, 36)\n        x = self.output_layer(x)  # (batch, 5, 128)\n        return x\n\nclass PsdTransformer(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n        super(PsdTransformer, self).__init__()\n        # PSD/DE input: (batch, 6_channels, 5_bands)\n        # Transpose to: (batch, 6, 5) - treat channels as sequence\n        \n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=input_dim,  # 5 bands\n            nhead=num_heads,\n            dim_feedforward=hidden_dim,\n            dropout=dropout,\n            batch_first=True,\n            activation=\"gelu\"\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n        self.output_layer = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        # x: (batch, 6_channels, 5_bands)\n        x = self.transformer(x)  # (batch, 6, 5)\n        x = self.output_layer(x)  # (batch, 6, 128)\n        return x\n\nclass FinalModel(nn.Module):\n    def __init__(self, \n                 pte_input_dim, pte_hidden_dim, pte_num_layers, pte_num_heads, pte_output_dim, pte_dropout,\n                 psd_input_dim, psd_hidden_dim, psd_num_layers, psd_num_heads, psd_output_dim, psd_dropout,\n                 cross_d_model, cross_num_heads):\n        super(FinalModel, self).__init__()\n        \n        self.pte_transformer = PteTransformer(\n            input_dim=pte_input_dim,\n            hidden_dim=pte_hidden_dim,\n            num_layers=pte_num_layers,\n            num_heads=pte_num_heads,\n            output_dim=pte_output_dim,\n            dropout=pte_dropout\n        )\n        \n        self.psd_transformer = PsdTransformer(\n            input_dim=psd_input_dim,\n            hidden_dim=psd_hidden_dim,\n            num_layers=psd_num_layers,\n            num_heads=psd_num_heads,\n            output_dim=psd_output_dim,\n            dropout=psd_dropout\n        )\n        \n        self.cross_attention = MultiHeadCrossAttention(\n            d_model=cross_d_model,\n            num_heads=cross_num_heads,\n            dropout=0.1\n        )\n        \n        # After cross attention: (batch, 5, 128)\n        # Flatten for classification: (batch, 5*128) = (batch, 640)\n        self.final_classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.5),\n            nn.Linear(5 * 128, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2)\n        )\n    \n    def forward(self, pte_input, psd_input):\n        # pte_input: (batch, 5, 6, 6)\n        # psd_input: (batch, 6, 5)\n        \n        pte_encoded = self.pte_transformer(pte_input)  # (batch, 5, 128)\n        psd_encoded = self.psd_transformer(psd_input)  # (batch, 6, 128)\n        \n        # Cross attention: query from PTE (5 band features), key/value from PSD (6 channel features)\n        cross_attn_output, attn_weights = self.cross_attention(\n            query=pte_encoded,  # (batch, 5, 128)\n            key=psd_encoded,    # (batch, 6, 128)\n            value=psd_encoded   # (batch, 6, 128)\n        )\n        # Output: (batch, 5, 128) - maintains query sequence length\n        \n        label_pred = self.final_classifier(cross_attn_output)  # (batch, 2)\n        \n        return label_pred, attn_weights\n\n# ═══════════════════════════════════════════════════════════════════════════\n# TRAINING AND EVALUATION\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef train_model(\n    model,\n    source_dataloader,\n    target_dataloader,\n    criterion_label,\n    optimizer,\n    num_epochs=10,\n    device=\"cuda\",\n    scheduler=None,\n):\n    model.to(device)\n    model.train()\n    \n    accuracy_history = []\n    \n    for epoch in range(num_epochs):\n        total_correct = 0\n        total_samples = 0\n        epoch_loss = 0.0\n        \n        for batch_src in source_dataloader:\n            if len(batch_src) == 4:\n                source_pte, source_psd, source_labels, _ = batch_src\n            else:\n                source_pte, source_psd, source_labels = batch_src[:3]\n            \n            source_pte = source_pte.to(device)\n            source_psd = source_psd.to(device)\n            source_labels = source_labels.to(device)\n            \n            label_preds, _ = model(source_pte, source_psd)\n            loss_label = criterion_label(label_preds, source_labels)\n            \n            optimizer.zero_grad()\n            loss_label.backward()\n            optimizer.step()\n            \n            epoch_loss += loss_label.item()\n            \n            _, predicted = torch.max(label_preds, dim=1)\n            correct = (predicted == source_labels).sum().item()\n            total_correct += correct\n            total_samples += source_labels.size(0)\n        \n        if scheduler is not None:\n            scheduler.step()\n        \n        epoch_accuracy = 100.0 * total_correct / total_samples if total_samples > 0 else 0\n        accuracy_history.append(epoch_accuracy)\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"  Epoch {epoch+1}/{num_epochs}: Loss={epoch_loss:.4f}, Acc={epoch_accuracy:.2f}%\")\n    \n    return accuracy_history\n\ndef test_model(\n    model,\n    test_dataloader,\n    criterion_label,\n    device=\"cuda\",\n    num_classes=2,\n    alz_threshold=0.4\n):\n    model.to(device).eval()\n    total_loss = 0.0\n    \n    all_preds = []\n    all_labels = []\n    all_probs = []\n    all_pids = []\n    \n    with torch.no_grad():\n        for batch in test_dataloader:\n            if len(batch) == 4:\n                pte, psd, labels, pids = batch\n            else:\n                pte, psd, labels = batch\n                pids = torch.zeros_like(labels)\n            \n            pte, psd, labels = pte.to(device), psd.to(device), labels.to(device)\n            logits, _ = model(pte, psd)\n            loss = criterion_label(logits, labels)\n            total_loss += loss.item()\n            \n            probs = F.softmax(logits, dim=1)\n            preds = probs.argmax(dim=1)\n            \n            all_probs.append(probs.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_pids.extend(pids.cpu().numpy())\n    \n    n_batches = len(test_dataloader)\n    avg_loss = total_loss / n_batches if n_batches else 0.0\n    \n    all_probs = np.vstack(all_probs)\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_pids = np.array(all_pids)\n    \n    part_ids = np.unique(all_pids)\n    part_accs = []\n    part_preds = []\n    part_confs = np.zeros((num_classes, num_classes), dtype=int)\n    part_ratios = []\n    part_trues = []\n    \n    for pid in part_ids:\n        mask = (all_pids == pid)\n        labs = all_labels[mask]\n        preds = all_preds[mask]\n        \n        true_lbl = labs[0]\n        alz_ratio = (preds == 1).sum() / max(len(preds), 1)\n        pred_lbl = 1 if alz_ratio >= alz_threshold else 0\n        \n        part_confs[true_lbl, pred_lbl] += 1\n        part_accs.append(100.0 if pred_lbl == true_lbl else 0.0)\n        \n        part_preds.append(pred_lbl)\n        part_ratios.append(alz_ratio)\n        part_trues.append(true_lbl)\n    \n    mean_acc = float(np.mean(part_accs)) if part_accs else 0.0\n    mean_f1 = f1_score(part_trues, part_preds, average='macro', zero_division=0) if part_trues else 0.0\n    \n    return (\n        avg_loss,\n        mean_acc,\n        mean_f1,\n        part_confs,\n        all_probs,\n        all_labels,\n        np.array(part_ratios),\n        np.array(part_trues)\n    )\n\ndef tune_threshold_on_source(\n    model,\n    source_dataloader,\n    device=\"cuda\",\n    thresholds=[0.1, 0.2, 0.3, 0.4, 0.5],\n    num_classes=2\n):\n    model.eval()\n    model.to(device)\n    sample_preds = defaultdict(list)\n    participant_label = {}\n    \n    with torch.no_grad():\n        for batch in source_dataloader:\n            if len(batch) == 4:\n                pte_batch, psd_batch, labels, pid_batch = batch\n            else:\n                raise ValueError(\"Expected Dataloader to return (pte, psd, labels, pid).\")\n            \n            pte_batch = pte_batch.to(device)\n            psd_batch = psd_batch.to(device)\n            labels = labels.to(device)\n            pid_batch = pid_batch.to(device)\n            \n            label_preds, _ = model(pte_batch, psd_batch)\n            softmax_output = F.softmax(label_preds, dim=1)\n            _, predicted = torch.max(softmax_output, dim=1)\n            \n            predicted = predicted.cpu().numpy()\n            labels = labels.cpu().numpy()\n            pid_batch = pid_batch.cpu().numpy()\n            \n            for pred, true_lbl, pid in zip(predicted, labels, pid_batch):\n                sample_preds[pid].append(pred)\n                if pid not in participant_label:\n                    participant_label[pid] = true_lbl\n    \n    best_threshold = None\n    best_metric_val = -1.0\n    \n    for thr in thresholds:\n        part_level_preds = []\n        part_level_trues = []\n        \n        for pid, preds_list in sample_preds.items():\n            true_lbl = participant_label[pid]\n            n_alz = sum([p == 1 for p in preds_list])\n            ratio = float(n_alz) / len(preds_list)\n            participant_pred = 1 if ratio >= thr else 0\n            \n            part_level_preds.append(participant_pred)\n            part_level_trues.append(true_lbl)\n        \n        f1 = f1_score(part_level_trues, part_level_preds, average='macro', zero_division=0)\n        acc = accuracy_score(part_level_trues, part_level_preds)\n        \n        print(f\"    [Threshold {thr}] -> F1={f1:.4f} | Acc={acc:.4f}\")\n        \n        if f1 > best_metric_val:\n            best_metric_val = f1\n            best_threshold = thr\n    \n    print(f\"    [Best Threshold] = {best_threshold} with F1={best_metric_val:.4f}\")\n    return best_threshold\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MAIN PIPELINE\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef extract_features():\n    \"\"\"Extract PTE and DE features from raw EEG data.\"\"\"\n    print(\"=\" * 80)\n    print(\"FEATURE EXTRACTION\")\n    print(\"=\" * 80)\n    \n    # Get file paths\n    all_paths = glob.glob(f\"{DATA_DIR}/sub-*/eeg/*.set\")\n    print(f\"Found {len(all_paths)} EEG files\")\n    \n    groups = {'alz': [], 'ctrl': [], 'ftd': []}\n    for fp in all_paths:\n        sid = get_subject_id(fp)\n        if sid is None:\n            continue\n        if sid <= 36:\n            groups['alz'].append(fp)\n        elif sid <= 65:\n            groups['ctrl'].append(fp)\n        else:\n            groups['ftd'].append(fp)\n    \n    print(f\"ALZ: {len(groups['alz'])}, CTRL: {len(groups['ctrl'])}, FTD: {len(groups['ftd'])}\")\n    \n    # Extract PTE features\n    print(\"\\n--- Extracting PTE features ---\")\n    for grp, paths in groups.items():\n        for fp in paths:\n            subj_id, dp, label = process_pte_subject(fp, grp)\n            out_f = os.path.join(FEATURES_DIR, f\"sub-{subj_id}_PTE_{grp}.npz\")\n            np.savez(out_f, pte_data=dp, subject_id=subj_id, label=label)\n            print(f\"  Saved {out_f}, shape={dp.shape}\")\n    \n    # Extract DE features\n    print(\"\\n--- Extracting DE features ---\")\n    for grp, paths in groups.items():\n        for fp in paths:\n            subj_id, de_vals, label = process_de_subject(fp, grp)\n            out_f = os.path.join(FEATURES_DIR, f\"sub-{subj_id}_DE_{grp}.npz\")\n            np.savez_compressed(out_f, DE_features=de_vals, subject_id=subj_id, label=label)\n            print(f\"  Saved {out_f}, shape={de_vals.shape}\")\n\ndef run_experiment(task='cn_ad'):\n    \"\"\"Run the complete experiment.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"RUNNING EXPERIMENT: {task.upper()}\")\n    print(\"=\" * 80)\n    \n    # Set seed\n    set_seed(0)\n    \n    # Configure task\n    if task == 'cn_ad':\n        selected_classes = [\"ctrl\", \"alz\"]\n        class_weights = torch.tensor([1.0, 0.7])\n        use_weights = True\n    elif task == 'cn_ftd':\n        selected_classes = [\"ctrl\", \"ftd\"]\n        class_weights = None\n        use_weights = False\n    else:\n        raise ValueError(f\"Unknown task: {task}\")\n    \n    # Model hyperparameters\n    pte_input_dim = 36  # Spatial dimension after flattening (6*6)\n    pte_hidden_dim = 512\n    pte_num_layers = 2\n    pte_num_heads = 4  # Must divide 36\n    pte_output_dim = 128\n    pte_dropout = 0.4\n    \n    psd_input_dim = 5  # Number of bands\n    psd_hidden_dim = 512\n    psd_num_layers = 2\n    psd_num_heads = 5  # Must divide 5\n    psd_output_dim = 128\n    psd_dropout = 0.4\n    \n    cross_d_model = 128\n    cross_num_heads = 8  # Must divide 128\n    \n    # Load data\n    print(\"\\n--- Loading data ---\")\n    all_folds = load_data_stratified_kfold(\n        pte_directory=FEATURES_DIR,\n        DE_directory=FEATURES_DIR,  # Both in same directory now\n        batch_size=BATCH_SIZE,\n        selected_classes=selected_classes,\n        selected_channels=SELECTED_CHANNELS,\n        n_splits=N_SPLITS,\n        n_repetitions=N_REPETITIONS,\n    )\n    \n    # Results storage\n    all_acc_final = []\n    all_f1_final = []\n    all_conf_final = []\n    global_probs_final = []\n    global_labels_final = []\n    best_thresholds_final = []\n    \n    # Device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Run experiments\n    for rep_idx, folds in enumerate(all_folds):\n        print(f\"\\n{'=' * 80}\")\n        print(f\"REPETITION {rep_idx + 1}/{len(all_folds)}\")\n        print(f\"{'=' * 80}\")\n        \n        all_acc = []\n        all_f1 = []\n        all_conf = []\n        global_probs = []\n        global_labels = []\n        best_thresholds = []\n        \n        for fold_idx, (train_loader, val_loader) in enumerate(folds, 1):\n            print(f\"\\n--- Fold {fold_idx}/{len(folds)} ---\")\n            \n            # Initialize model\n            model = FinalModel(\n                pte_input_dim=pte_input_dim,\n                pte_hidden_dim=pte_hidden_dim,\n                pte_num_layers=pte_num_layers,\n                pte_num_heads=pte_num_heads,\n                pte_output_dim=pte_output_dim,\n                pte_dropout=pte_dropout,\n                psd_input_dim=psd_input_dim,\n                psd_hidden_dim=psd_hidden_dim,\n                psd_num_layers=psd_num_layers,\n                psd_num_heads=psd_num_heads,\n                psd_output_dim=psd_output_dim,\n                psd_dropout=psd_dropout,\n                cross_d_model=cross_d_model,\n                cross_num_heads=cross_num_heads\n            )\n            model.to(device)\n            \n            # Loss and optimizer\n            if use_weights:\n                criterion_label = nn.CrossEntropyLoss(class_weights.to(device))\n            else:\n                criterion_label = nn.CrossEntropyLoss()\n            \n            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n            \n            # Train\n            print(\"Training...\")\n            label_acc_history = train_model(\n                model=model,\n                source_dataloader=train_loader,\n                target_dataloader=val_loader,\n                criterion_label=criterion_label,\n                optimizer=optimizer,\n                num_epochs=NUM_EPOCHS,\n                device=device,\n                scheduler=None,\n            )\n            print(f\"  Final training accuracy: {label_acc_history[-1]:.2f}%\")\n            \n            # Threshold tuning\n            print(\"  Tuning threshold...\")\n            thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n            best_thr = tune_threshold_on_source(\n                model=model,\n                source_dataloader=train_loader,\n                device=device,\n                thresholds=thresholds_to_try,\n                num_classes=2\n            )\n            best_thresholds.append(best_thr)\n            \n            # Test\n            print(\"  Testing...\")\n            test_loss, test_acc, test_f1, conf_mat, preds, labels, _, _ = test_model(\n                model=model,\n                test_dataloader=val_loader,\n                criterion_label=criterion_label,\n                device=device,\n                num_classes=2,\n                alz_threshold=best_thr\n            )\n            \n            print(f\"  Validation loss: {test_loss:.4f}\")\n            print(f\"  Validation accuracy: {test_acc:.2f}%\")\n            print(f\"  Validation F1: {test_f1:.4f}\")\n            \n            # Store results\n            all_acc.append(test_acc)\n            all_f1.append(test_f1)\n            all_conf.append(conf_mat)\n            global_probs.append(preds)\n            global_labels.append(labels)\n        \n        # Repetition results\n        all_acc_final.append(all_acc)\n        all_f1_final.append(all_f1)\n        all_conf_final.append(all_conf)\n        global_probs_final.append(global_probs)\n        global_labels_final.append(global_labels)\n        best_thresholds_final.append(best_thresholds)\n        \n        print(f\"\\n  Repetition {rep_idx + 1} Results:\")\n        print(f\"  Mean accuracy: {np.mean(all_acc):.2f}% ± {np.std(all_acc):.2f}%\")\n        print(f\"  Mean F1: {np.mean(all_f1):.4f} ± {np.std(all_f1):.4f}\")\n    \n    # Save results\n    final_results = {\n        \"all_acc\": all_acc_final,\n        \"all_f1\": all_f1_final,\n        \"all_conf\": all_conf_final,\n        \"global_probs\": global_probs_final,\n        \"global_labels\": global_labels_final,\n        \"best_thresholds\": best_thresholds_final\n    }\n    \n    results_file = os.path.join(RESULTS_DIR, f\"final_results_{task}_dtca.npz\")\n    np.savez(results_file, final_results=final_results)\n    print(f\"\\n✓ Saved results to {results_file}\")\n    \n    # Compute final metrics\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FINAL RESULTS\")\n    print(\"=\" * 80)\n    \n    compute_final_metrics(final_results)\n    \n    return final_results\n\ndef compute_final_metrics(final_results):\n    \"\"\"Compute and print final performance metrics.\"\"\"\n    all_runs = final_results[\"all_conf\"]\n    \n    acc_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n    \n    for run_idx, run_cms in enumerate(all_runs, start=1):\n        for fold_idx, cm in enumerate(run_cms, start=1):\n            cm = np.asarray(cm)\n            if cm.shape != (2, 2):\n                continue\n            \n            tn, fp, fn, tp = cm.ravel()\n            \n            y_true = np.array([0] * (tn + fp) + [1] * (fn + tp))\n            y_pred = np.array([0] * tn + [1] * fp + [0] * fn + [1] * tp)\n            \n            acc_scores.append(accuracy_score(y_true, y_pred))\n            precision_scores.append(precision_score(y_true, y_pred, zero_division=0))\n            recall_scores.append(recall_score(y_true, y_pred, zero_division=0))\n            f1_scores.append(f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n    \n    metrics = {\n        \"Accuracy\": (np.mean(acc_scores), np.std(acc_scores)),\n        \"Precision\": (np.mean(precision_scores), np.std(precision_scores)),\n        \"Recall\": (np.mean(recall_scores), np.std(recall_scores)),\n        \"F1-score\": (np.mean(f1_scores), np.std(f1_scores)),\n    }\n    \n    for name, (mean, std) in metrics.items():\n        print(f\"{name:12s}: {mean:.4f} ± {std:.4f}\")\n    \n    # Compute global AUC\n    gp = []\n    for i in range(len(final_results[\"global_probs\"])):\n        gp.extend(final_results[\"global_probs\"][i])\n    global_probs = np.vstack(gp)\n    \n    gl = []\n    for i in range(len(final_results[\"global_labels\"])):\n        gl.extend(final_results[\"global_labels\"][i])\n    global_labels = np.hstack(gl)\n    \n    global_auc = roc_auc_score(global_labels, global_probs[:, 1])\n    print(f\"\\nGlobal AUC: {global_auc:.4f}\")\n    \n    # Plot ROC curve\n    fpr, tpr, _ = roc_curve(global_labels, global_probs[:, 1])\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"AUC = {global_auc:.4f}\")\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(alpha=0.3)\n    plt.savefig(os.path.join(RESULTS_DIR, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"✓ Saved ROC curve to {RESULTS_DIR}/roc_curve.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MAIN EXECUTION\n# ═══════════════════════════════════════════════════════════════════════════\n\nif __name__ == \"__main__\":\n    print(\"=\" * 80)\n    print(\"DTCA-NET: DUAL-TRANSFORMER CROSS ATTENTION NETWORK\")\n    print(\"EEG-based Alzheimer's and Frontotemporal Dementia Detection\")\n    print(\"=\" * 80)\n    \n    # Step 1: Extract features (comment out if already extracted)\n    # print(\"\\n[1/3] Extracting features from raw EEG data...\")\n    extract_features()\n    \n    # Step 2: Run CN vs AD experiment\n    print(\"\\n[2/3] Running CN vs AD experiment...\")\n    results_cn_ad = run_experiment(task='cn_ad')\n    \n    # Step 3: Run CN vs FTD experiment\n    print(\"\\n[3/3] Running CN vs FTD experiment...\")\n    results_cn_ftd = run_experiment(task='cn_ftd')\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"EXPERIMENT COMPLETED SUCCESSFULLY\")\n    print(\"=\" * 80)\n    print(f\"Results saved in: {RESULTS_DIR}\")\n    print(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T07:15:11.282283Z","iopub.execute_input":"2025-10-13T07:15:11.282597Z","iopub.status.idle":"2025-10-13T17:56:44.886312Z","shell.execute_reply.started":"2025-10-13T07:15:11.282573Z","shell.execute_reply":"2025-10-13T17:56:44.885122Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nDTCA-NET: DUAL-TRANSFORMER CROSS ATTENTION NETWORK\nEEG-based Alzheimer's and Frontotemporal Dementia Detection\n================================================================================\n================================================================================\nFEATURE EXTRACTION\n================================================================================\nFound 88 EEG files\nALZ: 36, CTRL: 29, FTD: 23\n\n--- Extracting PTE features ---\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-003/eeg/sub-003_task-eyesclosed_eeg.set\n  Saved ./features/sub-3_PTE_alz.npz, shape=(5, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-012/eeg/sub-012_task-eyesclosed_eeg.set\n  Saved ./features/sub-12_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-015/eeg/sub-015_task-eyesclosed_eeg.set\n  Saved ./features/sub-15_PTE_alz.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-034/eeg/sub-034_task-eyesclosed_eeg.set\n  Saved ./features/sub-34_PTE_alz.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-010/eeg/sub-010_task-eyesclosed_eeg.set\n  Saved ./features/sub-10_PTE_alz.npz, shape=(21, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-025/eeg/sub-025_task-eyesclosed_eeg.set\n  Saved ./features/sub-25_PTE_alz.npz, shape=(11, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-033/eeg/sub-033_task-eyesclosed_eeg.set\n  Saved ./features/sub-33_PTE_alz.npz, shape=(11, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-014/eeg/sub-014_task-eyesclosed_eeg.set\n  Saved ./features/sub-14_PTE_alz.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-018/eeg/sub-018_task-eyesclosed_eeg.set\n  Saved ./features/sub-18_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-023/eeg/sub-023_task-eyesclosed_eeg.set\n  Saved ./features/sub-23_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-009/eeg/sub-009_task-eyesclosed_eeg.set\n  Saved ./features/sub-9_PTE_alz.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-004/eeg/sub-004_task-eyesclosed_eeg.set\n  Saved ./features/sub-4_PTE_alz.npz, shape=(11, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-002/eeg/sub-002_task-eyesclosed_eeg.set\n  Saved ./features/sub-2_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-021/eeg/sub-021_task-eyesclosed_eeg.set\n  Saved ./features/sub-21_PTE_alz.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-020/eeg/sub-020_task-eyesclosed_eeg.set\n  Saved ./features/sub-20_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-008/eeg/sub-008_task-eyesclosed_eeg.set\n  Saved ./features/sub-8_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-032/eeg/sub-032_task-eyesclosed_eeg.set\n  Saved ./features/sub-32_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-035/eeg/sub-035_task-eyesclosed_eeg.set\n  Saved ./features/sub-35_PTE_alz.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-027/eeg/sub-027_task-eyesclosed_eeg.set\n  Saved ./features/sub-27_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-006/eeg/sub-006_task-eyesclosed_eeg.set\n  Saved ./features/sub-6_PTE_alz.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-026/eeg/sub-026_task-eyesclosed_eeg.set\n  Saved ./features/sub-26_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-019/eeg/sub-019_task-eyesclosed_eeg.set\n  Saved ./features/sub-19_PTE_alz.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-011/eeg/sub-011_task-eyesclosed_eeg.set\n  Saved ./features/sub-11_PTE_alz.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-001/eeg/sub-001_task-eyesclosed_eeg.set\n  Saved ./features/sub-1_PTE_alz.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-022/eeg/sub-022_task-eyesclosed_eeg.set\n  Saved ./features/sub-22_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-013/eeg/sub-013_task-eyesclosed_eeg.set\n  Saved ./features/sub-13_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-031/eeg/sub-031_task-eyesclosed_eeg.set\n  Saved ./features/sub-31_PTE_alz.npz, shape=(19, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-024/eeg/sub-024_task-eyesclosed_eeg.set\n  Saved ./features/sub-24_PTE_alz.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-030/eeg/sub-030_task-eyesclosed_eeg.set\n  Saved ./features/sub-30_PTE_alz.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-005/eeg/sub-005_task-eyesclosed_eeg.set\n  Saved ./features/sub-5_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-016/eeg/sub-016_task-eyesclosed_eeg.set\n  Saved ./features/sub-16_PTE_alz.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-017/eeg/sub-017_task-eyesclosed_eeg.set\n  Saved ./features/sub-17_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-007/eeg/sub-007_task-eyesclosed_eeg.set\n  Saved ./features/sub-7_PTE_alz.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-029/eeg/sub-029_task-eyesclosed_eeg.set\n  Saved ./features/sub-29_PTE_alz.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-028/eeg/sub-028_task-eyesclosed_eeg.set\n  Saved ./features/sub-28_PTE_alz.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-036/eeg/sub-036_task-eyesclosed_eeg.set\n  Saved ./features/sub-36_PTE_alz.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-060/eeg/sub-060_task-eyesclosed_eeg.set\n  Saved ./features/sub-60_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-057/eeg/sub-057_task-eyesclosed_eeg.set\n  Saved ./features/sub-57_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-048/eeg/sub-048_task-eyesclosed_eeg.set\n  Saved ./features/sub-48_PTE_ctrl.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-043/eeg/sub-043_task-eyesclosed_eeg.set\n  Saved ./features/sub-43_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-059/eeg/sub-059_task-eyesclosed_eeg.set\n  Saved ./features/sub-59_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-039/eeg/sub-039_task-eyesclosed_eeg.set\n  Saved ./features/sub-39_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-049/eeg/sub-049_task-eyesclosed_eeg.set\n  Saved ./features/sub-49_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-055/eeg/sub-055_task-eyesclosed_eeg.set\n  Saved ./features/sub-55_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-051/eeg/sub-051_task-eyesclosed_eeg.set\n  Saved ./features/sub-51_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-050/eeg/sub-050_task-eyesclosed_eeg.set\n  Saved ./features/sub-50_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-041/eeg/sub-041_task-eyesclosed_eeg.set\n  Saved ./features/sub-41_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-042/eeg/sub-042_task-eyesclosed_eeg.set\n  Saved ./features/sub-42_PTE_ctrl.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-045/eeg/sub-045_task-eyesclosed_eeg.set\n  Saved ./features/sub-45_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-054/eeg/sub-054_task-eyesclosed_eeg.set\n  Saved ./features/sub-54_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-052/eeg/sub-052_task-eyesclosed_eeg.set\n  Saved ./features/sub-52_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-062/eeg/sub-062_task-eyesclosed_eeg.set\n  Saved ./features/sub-62_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-065/eeg/sub-065_task-eyesclosed_eeg.set\n  Saved ./features/sub-65_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-053/eeg/sub-053_task-eyesclosed_eeg.set\n  Saved ./features/sub-53_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-047/eeg/sub-047_task-eyesclosed_eeg.set\n  Saved ./features/sub-47_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-064/eeg/sub-064_task-eyesclosed_eeg.set\n  Saved ./features/sub-64_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-038/eeg/sub-038_task-eyesclosed_eeg.set\n  Saved ./features/sub-38_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-044/eeg/sub-044_task-eyesclosed_eeg.set\n  Saved ./features/sub-44_PTE_ctrl.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-061/eeg/sub-061_task-eyesclosed_eeg.set\n  Saved ./features/sub-61_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-063/eeg/sub-063_task-eyesclosed_eeg.set\n  Saved ./features/sub-63_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-058/eeg/sub-058_task-eyesclosed_eeg.set\n  Saved ./features/sub-58_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-046/eeg/sub-046_task-eyesclosed_eeg.set\n  Saved ./features/sub-46_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-056/eeg/sub-056_task-eyesclosed_eeg.set\n  Saved ./features/sub-56_PTE_ctrl.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-040/eeg/sub-040_task-eyesclosed_eeg.set\n  Saved ./features/sub-40_PTE_ctrl.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-037/eeg/sub-037_task-eyesclosed_eeg.set\n  Saved ./features/sub-37_PTE_ctrl.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-087/eeg/sub-087_task-eyesclosed_eeg.set\n  Saved ./features/sub-87_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-085/eeg/sub-085_task-eyesclosed_eeg.set\n  Saved ./features/sub-85_PTE_ftd.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-080/eeg/sub-080_task-eyesclosed_eeg.set\n  Saved ./features/sub-80_PTE_ftd.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-070/eeg/sub-070_task-eyesclosed_eeg.set\n  Saved ./features/sub-70_PTE_ftd.npz, shape=(7, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-071/eeg/sub-071_task-eyesclosed_eeg.set\n  Saved ./features/sub-71_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-079/eeg/sub-079_task-eyesclosed_eeg.set\n  Saved ./features/sub-79_PTE_ftd.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-081/eeg/sub-081_task-eyesclosed_eeg.set\n  Saved ./features/sub-81_PTE_ftd.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-082/eeg/sub-082_task-eyesclosed_eeg.set\n  Saved ./features/sub-82_PTE_ftd.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-078/eeg/sub-078_task-eyesclosed_eeg.set\n  Saved ./features/sub-78_PTE_ftd.npz, shape=(14, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-084/eeg/sub-084_task-eyesclosed_eeg.set\n  Saved ./features/sub-84_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-076/eeg/sub-076_task-eyesclosed_eeg.set\n  Saved ./features/sub-76_PTE_ftd.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-086/eeg/sub-086_task-eyesclosed_eeg.set\n  Saved ./features/sub-86_PTE_ftd.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-083/eeg/sub-083_task-eyesclosed_eeg.set\n  Saved ./features/sub-83_PTE_ftd.npz, shape=(15, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-068/eeg/sub-068_task-eyesclosed_eeg.set\n  Saved ./features/sub-68_PTE_ftd.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-077/eeg/sub-077_task-eyesclosed_eeg.set\n  Saved ./features/sub-77_PTE_ftd.npz, shape=(11, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-067/eeg/sub-067_task-eyesclosed_eeg.set\n  Saved ./features/sub-67_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-074/eeg/sub-074_task-eyesclosed_eeg.set\n  Saved ./features/sub-74_PTE_ftd.npz, shape=(16, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-075/eeg/sub-075_task-eyesclosed_eeg.set\n  Saved ./features/sub-75_PTE_ftd.npz, shape=(12, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-066/eeg/sub-066_task-eyesclosed_eeg.set\n  Saved ./features/sub-66_PTE_ftd.npz, shape=(9, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-072/eeg/sub-072_task-eyesclosed_eeg.set\n  Saved ./features/sub-72_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-088/eeg/sub-088_task-eyesclosed_eeg.set\n  Saved ./features/sub-88_PTE_ftd.npz, shape=(13, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-069/eeg/sub-069_task-eyesclosed_eeg.set\n  Saved ./features/sub-69_PTE_ftd.npz, shape=(10, 11, 5, 19, 19)\nProcessing PTE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-073/eeg/sub-073_task-eyesclosed_eeg.set\n  Saved ./features/sub-73_PTE_ftd.npz, shape=(14, 11, 5, 19, 19)\n\n--- Extracting DE features ---\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-003/eeg/sub-003_task-eyesclosed_eeg.set\n  Saved ./features/sub-3_DE_alz.npz, shape=(55, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-012/eeg/sub-012_task-eyesclosed_eeg.set\n  Saved ./features/sub-12_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-015/eeg/sub-015_task-eyesclosed_eeg.set\n  Saved ./features/sub-15_DE_alz.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-034/eeg/sub-034_task-eyesclosed_eeg.set\n  Saved ./features/sub-34_DE_alz.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-010/eeg/sub-010_task-eyesclosed_eeg.set\n  Saved ./features/sub-10_DE_alz.npz, shape=(231, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-025/eeg/sub-025_task-eyesclosed_eeg.set\n  Saved ./features/sub-25_DE_alz.npz, shape=(121, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-033/eeg/sub-033_task-eyesclosed_eeg.set\n  Saved ./features/sub-33_DE_alz.npz, shape=(121, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-014/eeg/sub-014_task-eyesclosed_eeg.set\n  Saved ./features/sub-14_DE_alz.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-018/eeg/sub-018_task-eyesclosed_eeg.set\n  Saved ./features/sub-18_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-023/eeg/sub-023_task-eyesclosed_eeg.set\n  Saved ./features/sub-23_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-009/eeg/sub-009_task-eyesclosed_eeg.set\n  Saved ./features/sub-9_DE_alz.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-004/eeg/sub-004_task-eyesclosed_eeg.set\n  Saved ./features/sub-4_DE_alz.npz, shape=(121, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-002/eeg/sub-002_task-eyesclosed_eeg.set\n  Saved ./features/sub-2_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-021/eeg/sub-021_task-eyesclosed_eeg.set\n  Saved ./features/sub-21_DE_alz.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-020/eeg/sub-020_task-eyesclosed_eeg.set\n  Saved ./features/sub-20_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-008/eeg/sub-008_task-eyesclosed_eeg.set\n  Saved ./features/sub-8_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-032/eeg/sub-032_task-eyesclosed_eeg.set\n  Saved ./features/sub-32_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-035/eeg/sub-035_task-eyesclosed_eeg.set\n  Saved ./features/sub-35_DE_alz.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-027/eeg/sub-027_task-eyesclosed_eeg.set\n  Saved ./features/sub-27_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-006/eeg/sub-006_task-eyesclosed_eeg.set\n  Saved ./features/sub-6_DE_alz.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-026/eeg/sub-026_task-eyesclosed_eeg.set\n  Saved ./features/sub-26_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-019/eeg/sub-019_task-eyesclosed_eeg.set\n  Saved ./features/sub-19_DE_alz.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-011/eeg/sub-011_task-eyesclosed_eeg.set\n  Saved ./features/sub-11_DE_alz.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-001/eeg/sub-001_task-eyesclosed_eeg.set\n  Saved ./features/sub-1_DE_alz.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-022/eeg/sub-022_task-eyesclosed_eeg.set\n  Saved ./features/sub-22_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-013/eeg/sub-013_task-eyesclosed_eeg.set\n  Saved ./features/sub-13_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-031/eeg/sub-031_task-eyesclosed_eeg.set\n  Saved ./features/sub-31_DE_alz.npz, shape=(209, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-024/eeg/sub-024_task-eyesclosed_eeg.set\n  Saved ./features/sub-24_DE_alz.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-030/eeg/sub-030_task-eyesclosed_eeg.set\n  Saved ./features/sub-30_DE_alz.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-005/eeg/sub-005_task-eyesclosed_eeg.set\n  Saved ./features/sub-5_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-016/eeg/sub-016_task-eyesclosed_eeg.set\n  Saved ./features/sub-16_DE_alz.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-017/eeg/sub-017_task-eyesclosed_eeg.set\n  Saved ./features/sub-17_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-007/eeg/sub-007_task-eyesclosed_eeg.set\n  Saved ./features/sub-7_DE_alz.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-029/eeg/sub-029_task-eyesclosed_eeg.set\n  Saved ./features/sub-29_DE_alz.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-028/eeg/sub-028_task-eyesclosed_eeg.set\n  Saved ./features/sub-28_DE_alz.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-036/eeg/sub-036_task-eyesclosed_eeg.set\n  Saved ./features/sub-36_DE_alz.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-060/eeg/sub-060_task-eyesclosed_eeg.set\n  Saved ./features/sub-60_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-057/eeg/sub-057_task-eyesclosed_eeg.set\n  Saved ./features/sub-57_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-048/eeg/sub-048_task-eyesclosed_eeg.set\n  Saved ./features/sub-48_DE_ctrl.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-043/eeg/sub-043_task-eyesclosed_eeg.set\n  Saved ./features/sub-43_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-059/eeg/sub-059_task-eyesclosed_eeg.set\n  Saved ./features/sub-59_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-039/eeg/sub-039_task-eyesclosed_eeg.set\n  Saved ./features/sub-39_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-049/eeg/sub-049_task-eyesclosed_eeg.set\n  Saved ./features/sub-49_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-055/eeg/sub-055_task-eyesclosed_eeg.set\n  Saved ./features/sub-55_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-051/eeg/sub-051_task-eyesclosed_eeg.set\n  Saved ./features/sub-51_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-050/eeg/sub-050_task-eyesclosed_eeg.set\n  Saved ./features/sub-50_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-041/eeg/sub-041_task-eyesclosed_eeg.set\n  Saved ./features/sub-41_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-042/eeg/sub-042_task-eyesclosed_eeg.set\n  Saved ./features/sub-42_DE_ctrl.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-045/eeg/sub-045_task-eyesclosed_eeg.set\n  Saved ./features/sub-45_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-054/eeg/sub-054_task-eyesclosed_eeg.set\n  Saved ./features/sub-54_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-052/eeg/sub-052_task-eyesclosed_eeg.set\n  Saved ./features/sub-52_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-062/eeg/sub-062_task-eyesclosed_eeg.set\n  Saved ./features/sub-62_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-065/eeg/sub-065_task-eyesclosed_eeg.set\n  Saved ./features/sub-65_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-053/eeg/sub-053_task-eyesclosed_eeg.set\n  Saved ./features/sub-53_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-047/eeg/sub-047_task-eyesclosed_eeg.set\n  Saved ./features/sub-47_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-064/eeg/sub-064_task-eyesclosed_eeg.set\n  Saved ./features/sub-64_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-038/eeg/sub-038_task-eyesclosed_eeg.set\n  Saved ./features/sub-38_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-044/eeg/sub-044_task-eyesclosed_eeg.set\n  Saved ./features/sub-44_DE_ctrl.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-061/eeg/sub-061_task-eyesclosed_eeg.set\n  Saved ./features/sub-61_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-063/eeg/sub-063_task-eyesclosed_eeg.set\n  Saved ./features/sub-63_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-058/eeg/sub-058_task-eyesclosed_eeg.set\n  Saved ./features/sub-58_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-046/eeg/sub-046_task-eyesclosed_eeg.set\n  Saved ./features/sub-46_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-056/eeg/sub-056_task-eyesclosed_eeg.set\n  Saved ./features/sub-56_DE_ctrl.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-040/eeg/sub-040_task-eyesclosed_eeg.set\n  Saved ./features/sub-40_DE_ctrl.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-037/eeg/sub-037_task-eyesclosed_eeg.set\n  Saved ./features/sub-37_DE_ctrl.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-087/eeg/sub-087_task-eyesclosed_eeg.set\n  Saved ./features/sub-87_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-085/eeg/sub-085_task-eyesclosed_eeg.set\n  Saved ./features/sub-85_DE_ftd.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-080/eeg/sub-080_task-eyesclosed_eeg.set\n  Saved ./features/sub-80_DE_ftd.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-070/eeg/sub-070_task-eyesclosed_eeg.set\n  Saved ./features/sub-70_DE_ftd.npz, shape=(77, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-071/eeg/sub-071_task-eyesclosed_eeg.set\n  Saved ./features/sub-71_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-079/eeg/sub-079_task-eyesclosed_eeg.set\n  Saved ./features/sub-79_DE_ftd.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-081/eeg/sub-081_task-eyesclosed_eeg.set\n  Saved ./features/sub-81_DE_ftd.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-082/eeg/sub-082_task-eyesclosed_eeg.set\n  Saved ./features/sub-82_DE_ftd.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-078/eeg/sub-078_task-eyesclosed_eeg.set\n  Saved ./features/sub-78_DE_ftd.npz, shape=(154, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-084/eeg/sub-084_task-eyesclosed_eeg.set\n  Saved ./features/sub-84_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-076/eeg/sub-076_task-eyesclosed_eeg.set\n  Saved ./features/sub-76_DE_ftd.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-086/eeg/sub-086_task-eyesclosed_eeg.set\n  Saved ./features/sub-86_DE_ftd.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-083/eeg/sub-083_task-eyesclosed_eeg.set\n  Saved ./features/sub-83_DE_ftd.npz, shape=(165, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-068/eeg/sub-068_task-eyesclosed_eeg.set\n  Saved ./features/sub-68_DE_ftd.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-077/eeg/sub-077_task-eyesclosed_eeg.set\n  Saved ./features/sub-77_DE_ftd.npz, shape=(121, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-067/eeg/sub-067_task-eyesclosed_eeg.set\n  Saved ./features/sub-67_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-074/eeg/sub-074_task-eyesclosed_eeg.set\n  Saved ./features/sub-74_DE_ftd.npz, shape=(176, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-075/eeg/sub-075_task-eyesclosed_eeg.set\n  Saved ./features/sub-75_DE_ftd.npz, shape=(132, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-066/eeg/sub-066_task-eyesclosed_eeg.set\n  Saved ./features/sub-66_DE_ftd.npz, shape=(99, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-072/eeg/sub-072_task-eyesclosed_eeg.set\n  Saved ./features/sub-72_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-088/eeg/sub-088_task-eyesclosed_eeg.set\n  Saved ./features/sub-88_DE_ftd.npz, shape=(143, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-069/eeg/sub-069_task-eyesclosed_eeg.set\n  Saved ./features/sub-69_DE_ftd.npz, shape=(110, 19, 5)\nProcessing DE: /kaggle/input/openneuro-ds004504/ds004504/derivatives/sub-073/eeg/sub-073_task-eyesclosed_eeg.set\n  Saved ./features/sub-73_DE_ftd.npz, shape=(154, 19, 5)\n\n[2/3] Running CN vs AD experiment...\n\n================================================================================\nRUNNING EXPERIMENT: CN_AD\n================================================================================\nSeed set to: 0\n\n--- Loading data ---\nData shapes - PTE: (8096, 5, 6, 6), DE: (8096, 6, 5), Labels: (8096,)\nUsing device: cuda\n\n================================================================================\nREPETITION 1/10\n================================================================================\n\n--- Fold 1/10 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training...\n  Epoch 10/100: Loss=136.9651, Acc=72.81%\n  Epoch 20/100: Loss=126.4657, Acc=75.37%\n  Epoch 30/100: Loss=117.8258, Acc=77.41%\n  Epoch 40/100: Loss=113.3589, Acc=78.88%\n  Epoch 50/100: Loss=110.9894, Acc=79.27%\n  Epoch 60/100: Loss=108.7706, Acc=79.67%\n  Epoch 70/100: Loss=106.4521, Acc=80.74%\n  Epoch 80/100: Loss=103.6724, Acc=81.14%\n  Epoch 90/100: Loss=101.0485, Acc=81.67%\n  Epoch 100/100: Loss=99.7527, Acc=81.97%\n  Final training accuracy: 81.97%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8711 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9583 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 1.0170\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.7621, Acc=72.92%\n  Epoch 20/100: Loss=126.4667, Acc=75.28%\n  Epoch 30/100: Loss=120.2551, Acc=76.95%\n  Epoch 40/100: Loss=116.2380, Acc=78.68%\n  Epoch 50/100: Loss=114.3855, Acc=78.16%\n  Epoch 60/100: Loss=109.1831, Acc=79.88%\n  Epoch 70/100: Loss=106.5173, Acc=80.81%\n  Epoch 80/100: Loss=103.9495, Acc=81.25%\n  Epoch 90/100: Loss=102.2711, Acc=81.52%\n  Epoch 100/100: Loss=99.0521, Acc=82.05%\n  Final training accuracy: 82.05%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9588 | Acc=0.9592\n    [Best Threshold] = 0.4 with F1=0.9790\n  Testing...\n  Validation loss: 1.0682\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=152.4201, Acc=68.41%\n  Epoch 20/100: Loss=135.8877, Acc=73.49%\n  Epoch 30/100: Loss=129.7515, Acc=75.08%\n  Epoch 40/100: Loss=125.7340, Acc=76.43%\n  Epoch 50/100: Loss=121.4586, Acc=77.19%\n  Epoch 60/100: Loss=118.6769, Acc=78.26%\n  Epoch 70/100: Loss=115.7053, Acc=78.79%\n  Epoch 80/100: Loss=110.9251, Acc=80.05%\n  Epoch 90/100: Loss=108.4711, Acc=80.29%\n  Epoch 100/100: Loss=106.7281, Acc=81.36%\n  Final training accuracy: 81.36%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=1.0000 | Acc=1.0000\n    [Threshold 0.5] -> F1=0.9588 | Acc=0.9592\n    [Best Threshold] = 0.4 with F1=1.0000\n  Testing...\n  Validation loss: 0.4075\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.8113, Acc=73.07%\n  Epoch 20/100: Loss=133.0348, Acc=74.11%\n  Epoch 30/100: Loss=127.1331, Acc=75.77%\n  Epoch 40/100: Loss=123.4226, Acc=76.93%\n  Epoch 50/100: Loss=119.2861, Acc=77.74%\n  Epoch 60/100: Loss=117.0987, Acc=78.44%\n  Epoch 70/100: Loss=114.4110, Acc=78.84%\n  Epoch 80/100: Loss=111.7714, Acc=79.97%\n  Epoch 90/100: Loss=110.1483, Acc=80.10%\n  Epoch 100/100: Loss=106.3834, Acc=81.44%\n  Final training accuracy: 81.44%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9583 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.6359\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.8900, Acc=71.52%\n  Epoch 20/100: Loss=132.2735, Acc=74.16%\n  Epoch 30/100: Loss=127.0738, Acc=75.23%\n  Epoch 40/100: Loss=121.2700, Acc=76.88%\n  Epoch 50/100: Loss=115.5330, Acc=78.11%\n  Epoch 60/100: Loss=111.1337, Acc=79.46%\n  Epoch 70/100: Loss=110.2262, Acc=79.40%\n  Epoch 80/100: Loss=105.8110, Acc=80.65%\n  Epoch 90/100: Loss=104.4699, Acc=80.98%\n  Epoch 100/100: Loss=100.6472, Acc=81.85%\n  Final training accuracy: 81.85%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=1.0000 | Acc=1.0000\n    [Best Threshold] = 0.5 with F1=1.0000\n  Testing...\n  Validation loss: 0.4638\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.8186, Acc=72.18%\n  Epoch 20/100: Loss=126.7850, Acc=75.65%\n  Epoch 30/100: Loss=122.3845, Acc=76.68%\n  Epoch 40/100: Loss=117.5462, Acc=77.81%\n  Epoch 50/100: Loss=116.0644, Acc=78.15%\n  Epoch 60/100: Loss=112.6992, Acc=79.09%\n  Epoch 70/100: Loss=109.2284, Acc=79.83%\n  Epoch 80/100: Loss=105.3033, Acc=80.69%\n  Epoch 90/100: Loss=103.9674, Acc=81.19%\n  Epoch 100/100: Loss=102.7590, Acc=81.31%\n  Final training accuracy: 81.31%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9594\n  Testing...\n  Validation loss: 0.4923\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.6236, Acc=72.30%\n  Epoch 20/100: Loss=129.0420, Acc=74.90%\n  Epoch 30/100: Loss=124.6698, Acc=76.42%\n  Epoch 40/100: Loss=121.2190, Acc=76.51%\n  Epoch 50/100: Loss=118.1602, Acc=77.54%\n  Epoch 60/100: Loss=115.2036, Acc=78.65%\n  Epoch 70/100: Loss=110.9696, Acc=79.06%\n  Epoch 80/100: Loss=109.9865, Acc=79.46%\n  Epoch 90/100: Loss=106.6746, Acc=80.12%\n  Epoch 100/100: Loss=105.9386, Acc=80.09%\n  Final training accuracy: 80.09%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.5] -> F1=0.9380 | Acc=0.9400\n    [Best Threshold] = 0.5 with F1=0.9380\n  Testing...\n  Validation loss: 0.5989\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.5180, Acc=71.54%\n  Epoch 20/100: Loss=128.4128, Acc=74.27%\n  Epoch 30/100: Loss=121.8867, Acc=76.45%\n  Epoch 40/100: Loss=118.8044, Acc=77.77%\n  Epoch 50/100: Loss=113.2822, Acc=78.42%\n  Epoch 60/100: Loss=111.5966, Acc=79.20%\n  Epoch 70/100: Loss=109.9300, Acc=79.68%\n  Epoch 80/100: Loss=106.8666, Acc=80.06%\n  Epoch 90/100: Loss=104.5939, Acc=80.87%\n  Epoch 100/100: Loss=102.8795, Acc=81.15%\n  Final training accuracy: 81.15%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.6160\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.6330, Acc=71.96%\n  Epoch 20/100: Loss=126.0531, Acc=74.42%\n  Epoch 30/100: Loss=122.2562, Acc=75.58%\n  Epoch 40/100: Loss=119.1700, Acc=76.58%\n  Epoch 50/100: Loss=115.3877, Acc=77.81%\n  Epoch 60/100: Loss=111.2868, Acc=79.25%\n  Epoch 70/100: Loss=110.4422, Acc=78.70%\n  Epoch 80/100: Loss=107.0008, Acc=79.69%\n  Epoch 90/100: Loss=104.5106, Acc=80.75%\n  Epoch 100/100: Loss=103.6820, Acc=80.27%\n  Final training accuracy: 80.27%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8264 | Acc=0.8400\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9388 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9394 | Acc=0.9400\n    [Best Threshold] = 0.5 with F1=0.9394\n  Testing...\n  Validation loss: 0.7353\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=149.5821, Acc=69.22%\n  Epoch 20/100: Loss=140.9978, Acc=71.64%\n  Epoch 30/100: Loss=134.6684, Acc=73.29%\n  Epoch 40/100: Loss=128.9984, Acc=74.78%\n  Epoch 50/100: Loss=126.0317, Acc=75.71%\n  Epoch 60/100: Loss=121.6880, Acc=76.72%\n  Epoch 70/100: Loss=118.3871, Acc=77.86%\n  Epoch 80/100: Loss=115.6106, Acc=77.93%\n  Epoch 90/100: Loss=111.8234, Acc=79.80%\n  Epoch 100/100: Loss=110.3944, Acc=79.27%\n  Final training accuracy: 79.27%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8264 | Acc=0.8400\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9388 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9597 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9597\n  Testing...\n  Validation loss: 0.4068\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n  Repetition 1 Results:\n  Mean accuracy: 82.00% ± 13.92%\n  Mean F1: 0.8136 ± 0.1427\n\n================================================================================\nREPETITION 2/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.9247, Acc=70.41%\n  Epoch 20/100: Loss=130.5611, Acc=72.84%\n  Epoch 30/100: Loss=125.6930, Acc=74.73%\n  Epoch 40/100: Loss=121.2100, Acc=75.90%\n  Epoch 50/100: Loss=117.3209, Acc=76.86%\n  Epoch 60/100: Loss=113.5526, Acc=77.46%\n  Epoch 70/100: Loss=111.0557, Acc=78.41%\n  Epoch 80/100: Loss=107.4664, Acc=79.34%\n  Epoch 90/100: Loss=105.7521, Acc=79.80%\n  Epoch 100/100: Loss=102.5321, Acc=80.32%\n  Final training accuracy: 80.32%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8935 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9793 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9795 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9795\n  Testing...\n  Validation loss: 0.4792\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.9609, Acc=71.64%\n  Epoch 20/100: Loss=130.8430, Acc=73.80%\n  Epoch 30/100: Loss=126.5866, Acc=75.35%\n  Epoch 40/100: Loss=121.7630, Acc=76.63%\n  Epoch 50/100: Loss=117.7996, Acc=77.39%\n  Epoch 60/100: Loss=112.7508, Acc=78.86%\n  Epoch 70/100: Loss=109.2167, Acc=79.63%\n  Epoch 80/100: Loss=104.5554, Acc=81.36%\n  Epoch 90/100: Loss=103.4090, Acc=81.12%\n  Epoch 100/100: Loss=99.2708, Acc=82.29%\n  Final training accuracy: 82.29%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8199 | Acc=0.8367\n    [Threshold 0.3] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9578 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9578\n  Testing...\n  Validation loss: 0.8869\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=143.4553, Acc=71.28%\n  Epoch 20/100: Loss=132.8628, Acc=74.96%\n  Epoch 30/100: Loss=126.1460, Acc=76.24%\n  Epoch 40/100: Loss=123.1315, Acc=77.34%\n  Epoch 50/100: Loss=118.5744, Acc=78.61%\n  Epoch 60/100: Loss=113.2413, Acc=79.64%\n  Epoch 70/100: Loss=111.3789, Acc=80.27%\n  Epoch 80/100: Loss=108.6218, Acc=80.56%\n  Epoch 90/100: Loss=106.6786, Acc=81.29%\n  Epoch 100/100: Loss=104.4860, Acc=81.49%\n  Final training accuracy: 81.49%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.5309\n  Validation accuracy: 66.67%\n  Validation F1: 0.6250\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.8925, Acc=72.59%\n  Epoch 20/100: Loss=128.7346, Acc=74.08%\n  Epoch 30/100: Loss=122.3982, Acc=76.18%\n  Epoch 40/100: Loss=118.3303, Acc=77.42%\n  Epoch 50/100: Loss=116.4695, Acc=77.56%\n  Epoch 60/100: Loss=111.4513, Acc=79.08%\n  Epoch 70/100: Loss=109.5872, Acc=79.50%\n  Epoch 80/100: Loss=107.3866, Acc=80.07%\n  Epoch 90/100: Loss=105.1112, Acc=80.46%\n  Epoch 100/100: Loss=103.0984, Acc=80.87%\n  Final training accuracy: 80.87%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8444 | Acc=0.8571\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.5052\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.4841, Acc=73.88%\n  Epoch 20/100: Loss=123.2905, Acc=76.89%\n  Epoch 30/100: Loss=119.2603, Acc=77.60%\n  Epoch 40/100: Loss=114.3041, Acc=79.18%\n  Epoch 50/100: Loss=110.0896, Acc=79.53%\n  Epoch 60/100: Loss=106.9121, Acc=80.74%\n  Epoch 70/100: Loss=105.5153, Acc=80.99%\n  Epoch 80/100: Loss=103.0933, Acc=81.60%\n  Epoch 90/100: Loss=101.2460, Acc=82.02%\n  Epoch 100/100: Loss=98.3754, Acc=82.56%\n  Final training accuracy: 82.56%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9378 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9384 | Acc=0.9388\n    [Best Threshold] = 0.5 with F1=0.9384\n  Testing...\n  Validation loss: 0.5864\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.8632, Acc=70.01%\n  Epoch 20/100: Loss=133.8827, Acc=72.62%\n  Epoch 30/100: Loss=129.1317, Acc=74.70%\n  Epoch 40/100: Loss=124.0767, Acc=76.08%\n  Epoch 50/100: Loss=121.5128, Acc=76.58%\n  Epoch 60/100: Loss=118.4231, Acc=77.53%\n  Epoch 70/100: Loss=115.0868, Acc=78.46%\n  Epoch 80/100: Loss=112.0559, Acc=79.05%\n  Epoch 90/100: Loss=109.6830, Acc=79.62%\n  Epoch 100/100: Loss=108.6078, Acc=79.78%\n  Final training accuracy: 79.78%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.3] -> F1=0.9179 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9594 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9000 | Acc=0.9000\n    [Best Threshold] = 0.4 with F1=0.9594\n  Testing...\n  Validation loss: 0.3378\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=147.2664, Acc=68.57%\n  Epoch 20/100: Loss=133.8735, Acc=72.40%\n  Epoch 30/100: Loss=128.1061, Acc=75.25%\n  Epoch 40/100: Loss=122.4839, Acc=76.31%\n  Epoch 50/100: Loss=118.8748, Acc=77.42%\n  Epoch 60/100: Loss=114.1393, Acc=78.90%\n  Epoch 70/100: Loss=110.5164, Acc=79.85%\n  Epoch 80/100: Loss=109.1755, Acc=79.92%\n  Epoch 90/100: Loss=106.5020, Acc=80.45%\n  Epoch 100/100: Loss=104.5172, Acc=81.09%\n  Final training accuracy: 81.09%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.3] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.4] -> F1=0.9798 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9199 | Acc=0.9200\n    [Best Threshold] = 0.4 with F1=0.9798\n  Testing...\n  Validation loss: 0.6850\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.9621, Acc=71.58%\n  Epoch 20/100: Loss=132.9847, Acc=73.36%\n  Epoch 30/100: Loss=127.8472, Acc=74.59%\n  Epoch 40/100: Loss=123.9459, Acc=76.09%\n  Epoch 50/100: Loss=120.2940, Acc=76.89%\n  Epoch 60/100: Loss=117.7317, Acc=77.43%\n  Epoch 70/100: Loss=115.7080, Acc=77.61%\n  Epoch 80/100: Loss=110.4977, Acc=79.51%\n  Epoch 90/100: Loss=108.2545, Acc=79.95%\n  Epoch 100/100: Loss=106.0808, Acc=80.14%\n  Final training accuracy: 80.14%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.4999\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.1784, Acc=73.30%\n  Epoch 20/100: Loss=123.1117, Acc=76.67%\n  Epoch 30/100: Loss=117.7073, Acc=77.83%\n  Epoch 40/100: Loss=114.5711, Acc=79.12%\n  Epoch 50/100: Loss=109.1864, Acc=80.35%\n  Epoch 60/100: Loss=106.7480, Acc=80.65%\n  Epoch 70/100: Loss=105.6772, Acc=80.62%\n  Epoch 80/100: Loss=102.2367, Acc=81.54%\n  Epoch 90/100: Loss=100.5584, Acc=81.82%\n  Epoch 100/100: Loss=98.2118, Acc=82.34%\n  Final training accuracy: 82.34%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.9162\n  Validation accuracy: 40.00%\n  Validation F1: 0.4000\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=130.7722, Acc=73.67%\n  Epoch 20/100: Loss=123.9141, Acc=76.11%\n  Epoch 30/100: Loss=120.0703, Acc=77.34%\n  Epoch 40/100: Loss=116.9418, Acc=78.12%\n  Epoch 50/100: Loss=114.1839, Acc=78.83%\n  Epoch 60/100: Loss=112.8572, Acc=79.20%\n  Epoch 70/100: Loss=110.6658, Acc=79.46%\n  Epoch 80/100: Loss=106.4770, Acc=80.49%\n  Epoch 90/100: Loss=105.3828, Acc=80.99%\n  Epoch 100/100: Loss=103.6346, Acc=81.35%\n  Final training accuracy: 81.35%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 1.3138\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n  Repetition 2 Results:\n  Mean accuracy: 77.67% ± 18.74%\n  Mean F1: 0.7665 ± 0.1914\n\n================================================================================\nREPETITION 3/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.0513, Acc=69.87%\n  Epoch 20/100: Loss=131.6120, Acc=72.15%\n  Epoch 30/100: Loss=125.4534, Acc=74.79%\n  Epoch 40/100: Loss=121.4355, Acc=75.94%\n  Epoch 50/100: Loss=118.2736, Acc=76.44%\n  Epoch 60/100: Loss=115.0763, Acc=77.65%\n  Epoch 70/100: Loss=111.7721, Acc=78.20%\n  Epoch 80/100: Loss=108.0072, Acc=79.18%\n  Epoch 90/100: Loss=106.2157, Acc=79.52%\n  Epoch 100/100: Loss=103.0271, Acc=80.94%\n  Final training accuracy: 80.94%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9588 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9387 | Acc=0.9388\n    [Best Threshold] = 0.4 with F1=0.9588\n  Testing...\n  Validation loss: 0.4384\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.7556, Acc=72.58%\n  Epoch 20/100: Loss=126.5040, Acc=74.65%\n  Epoch 30/100: Loss=120.4596, Acc=76.74%\n  Epoch 40/100: Loss=116.4162, Acc=77.83%\n  Epoch 50/100: Loss=112.0245, Acc=79.29%\n  Epoch 60/100: Loss=109.8419, Acc=79.17%\n  Epoch 70/100: Loss=107.4600, Acc=79.87%\n  Epoch 80/100: Loss=104.9655, Acc=80.65%\n  Epoch 90/100: Loss=102.9834, Acc=81.00%\n  Epoch 100/100: Loss=101.2534, Acc=81.52%\n  Final training accuracy: 81.52%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.6397\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.1825, Acc=71.89%\n  Epoch 20/100: Loss=134.3879, Acc=74.00%\n  Epoch 30/100: Loss=128.7152, Acc=75.33%\n  Epoch 40/100: Loss=123.9368, Acc=76.27%\n  Epoch 50/100: Loss=120.4366, Acc=77.92%\n  Epoch 60/100: Loss=116.2417, Acc=77.92%\n  Epoch 70/100: Loss=113.7758, Acc=79.04%\n  Epoch 80/100: Loss=110.3087, Acc=79.78%\n  Epoch 90/100: Loss=105.5850, Acc=81.12%\n  Epoch 100/100: Loss=102.1036, Acc=81.61%\n  Final training accuracy: 81.61%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8199 | Acc=0.8367\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9578 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9578\n  Testing...\n  Validation loss: 0.7208\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=132.4089, Acc=73.01%\n  Epoch 20/100: Loss=122.3247, Acc=75.26%\n  Epoch 30/100: Loss=117.9996, Acc=76.96%\n  Epoch 40/100: Loss=113.5770, Acc=78.13%\n  Epoch 50/100: Loss=109.7719, Acc=78.83%\n  Epoch 60/100: Loss=109.0654, Acc=78.52%\n  Epoch 70/100: Loss=106.6010, Acc=79.73%\n  Epoch 80/100: Loss=103.3615, Acc=80.73%\n  Epoch 90/100: Loss=101.3007, Acc=81.11%\n  Epoch 100/100: Loss=99.6435, Acc=81.17%\n  Final training accuracy: 81.17%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.7913\n  Validation accuracy: 66.67%\n  Validation F1: 0.6250\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.4707, Acc=69.11%\n  Epoch 20/100: Loss=134.0151, Acc=72.47%\n  Epoch 30/100: Loss=126.7548, Acc=75.23%\n  Epoch 40/100: Loss=122.6101, Acc=76.51%\n  Epoch 50/100: Loss=118.3074, Acc=77.25%\n  Epoch 60/100: Loss=114.6998, Acc=78.48%\n  Epoch 70/100: Loss=111.6181, Acc=79.76%\n  Epoch 80/100: Loss=108.3281, Acc=79.84%\n  Epoch 90/100: Loss=105.6700, Acc=81.16%\n  Epoch 100/100: Loss=104.4558, Acc=81.14%\n  Final training accuracy: 81.14%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8444 | Acc=0.8571\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.5] -> F1=1.0000 | Acc=1.0000\n    [Best Threshold] = 0.5 with F1=1.0000\n  Testing...\n  Validation loss: 0.4874\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=137.5978, Acc=73.85%\n  Epoch 20/100: Loss=127.2380, Acc=76.79%\n  Epoch 30/100: Loss=123.1011, Acc=77.59%\n  Epoch 40/100: Loss=118.7627, Acc=78.96%\n  Epoch 50/100: Loss=116.0407, Acc=79.38%\n  Epoch 60/100: Loss=112.2173, Acc=80.47%\n  Epoch 70/100: Loss=111.2114, Acc=80.52%\n  Epoch 80/100: Loss=108.9020, Acc=80.67%\n  Epoch 90/100: Loss=106.0617, Acc=82.11%\n  Epoch 100/100: Loss=104.9667, Acc=81.84%\n  Final training accuracy: 81.84%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9394 | Acc=0.9400\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 1.1111\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=133.1232, Acc=73.71%\n  Epoch 20/100: Loss=121.2718, Acc=77.12%\n  Epoch 30/100: Loss=116.4054, Acc=78.45%\n  Epoch 40/100: Loss=111.2021, Acc=79.38%\n  Epoch 50/100: Loss=106.7685, Acc=80.75%\n  Epoch 60/100: Loss=103.9920, Acc=81.26%\n  Epoch 70/100: Loss=102.1127, Acc=81.52%\n  Epoch 80/100: Loss=99.5050, Acc=82.59%\n  Epoch 90/100: Loss=97.7331, Acc=82.51%\n  Epoch 100/100: Loss=95.7267, Acc=83.24%\n  Final training accuracy: 83.24%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9594\n  Testing...\n  Validation loss: 0.9112\n  Validation accuracy: 40.00%\n  Validation F1: 0.4000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.6751, Acc=73.17%\n  Epoch 20/100: Loss=127.0614, Acc=75.73%\n  Epoch 30/100: Loss=123.7480, Acc=76.86%\n  Epoch 40/100: Loss=116.3884, Acc=78.77%\n  Epoch 50/100: Loss=115.1501, Acc=79.04%\n  Epoch 60/100: Loss=110.6087, Acc=80.61%\n  Epoch 70/100: Loss=106.4831, Acc=80.87%\n  Epoch 80/100: Loss=105.5079, Acc=81.32%\n  Epoch 90/100: Loss=100.7677, Acc=82.07%\n  Epoch 100/100: Loss=100.2314, Acc=82.17%\n  Final training accuracy: 82.17%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.6739\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=147.5847, Acc=70.33%\n  Epoch 20/100: Loss=137.4586, Acc=72.55%\n  Epoch 30/100: Loss=132.0483, Acc=73.83%\n  Epoch 40/100: Loss=126.9754, Acc=75.55%\n  Epoch 50/100: Loss=122.6043, Acc=76.51%\n  Epoch 60/100: Loss=119.1410, Acc=77.31%\n  Epoch 70/100: Loss=114.8735, Acc=78.55%\n  Epoch 80/100: Loss=112.3844, Acc=79.19%\n  Epoch 90/100: Loss=109.2433, Acc=79.76%\n  Epoch 100/100: Loss=107.8868, Acc=80.11%\n  Final training accuracy: 80.11%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9394 | Acc=0.9400\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 0.4018\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.8184, Acc=73.11%\n  Epoch 20/100: Loss=128.4262, Acc=75.35%\n  Epoch 30/100: Loss=123.4249, Acc=76.67%\n  Epoch 40/100: Loss=120.6539, Acc=77.40%\n  Epoch 50/100: Loss=115.2016, Acc=78.62%\n  Epoch 60/100: Loss=113.3743, Acc=79.36%\n  Epoch 70/100: Loss=110.4441, Acc=79.90%\n  Epoch 80/100: Loss=108.1848, Acc=79.86%\n  Epoch 90/100: Loss=106.3400, Acc=80.37%\n  Epoch 100/100: Loss=104.8353, Acc=80.77%\n  Final training accuracy: 80.77%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.6876\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n  Repetition 3 Results:\n  Mean accuracy: 75.67% ± 17.95%\n  Mean F1: 0.7439 ± 0.1836\n\n================================================================================\nREPETITION 4/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=133.8671, Acc=73.55%\n  Epoch 20/100: Loss=125.1606, Acc=75.85%\n  Epoch 30/100: Loss=119.0456, Acc=76.99%\n  Epoch 40/100: Loss=116.1242, Acc=77.73%\n  Epoch 50/100: Loss=113.5117, Acc=78.43%\n  Epoch 60/100: Loss=110.5892, Acc=79.21%\n  Epoch 70/100: Loss=108.1289, Acc=79.55%\n  Epoch 80/100: Loss=104.3287, Acc=80.90%\n  Epoch 90/100: Loss=102.7896, Acc=81.12%\n  Epoch 100/100: Loss=100.3902, Acc=81.65%\n  Final training accuracy: 81.65%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8480 | Acc=0.8571\n    [Threshold 0.3] -> F1=0.8935 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.5732\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.3493, Acc=71.71%\n  Epoch 20/100: Loss=131.1164, Acc=74.46%\n  Epoch 30/100: Loss=126.2034, Acc=75.93%\n  Epoch 40/100: Loss=121.9427, Acc=77.02%\n  Epoch 50/100: Loss=118.9529, Acc=77.51%\n  Epoch 60/100: Loss=113.8627, Acc=78.75%\n  Epoch 70/100: Loss=111.3138, Acc=79.53%\n  Epoch 80/100: Loss=108.6167, Acc=80.07%\n  Epoch 90/100: Loss=104.6632, Acc=80.83%\n  Epoch 100/100: Loss=102.8764, Acc=81.28%\n  Final training accuracy: 81.28%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.7944 | Acc=0.8163\n    [Threshold 0.3] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.4] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9578 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9578\n  Testing...\n  Validation loss: 0.6117\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=124.5033, Acc=75.90%\n  Epoch 20/100: Loss=117.2957, Acc=77.92%\n  Epoch 30/100: Loss=113.9017, Acc=78.52%\n  Epoch 40/100: Loss=109.9484, Acc=79.44%\n  Epoch 50/100: Loss=108.8682, Acc=80.02%\n  Epoch 60/100: Loss=105.2597, Acc=80.46%\n  Epoch 70/100: Loss=105.4458, Acc=80.59%\n  Epoch 80/100: Loss=103.2071, Acc=81.43%\n  Epoch 90/100: Loss=101.6518, Acc=81.55%\n  Epoch 100/100: Loss=100.0592, Acc=81.93%\n  Final training accuracy: 81.93%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 1.1287\n  Validation accuracy: 33.33%\n  Validation F1: 0.3333\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.4251, Acc=73.40%\n  Epoch 20/100: Loss=128.8782, Acc=74.71%\n  Epoch 30/100: Loss=124.4876, Acc=75.93%\n  Epoch 40/100: Loss=118.3579, Acc=77.55%\n  Epoch 50/100: Loss=114.8722, Acc=77.93%\n  Epoch 60/100: Loss=112.9204, Acc=79.12%\n  Epoch 70/100: Loss=108.4455, Acc=80.00%\n  Epoch 80/100: Loss=106.0304, Acc=80.11%\n  Epoch 90/100: Loss=102.7106, Acc=81.18%\n  Epoch 100/100: Loss=101.7809, Acc=81.07%\n  Final training accuracy: 81.07%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.8658\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=137.3365, Acc=72.44%\n  Epoch 20/100: Loss=126.8335, Acc=75.34%\n  Epoch 30/100: Loss=122.6864, Acc=76.48%\n  Epoch 40/100: Loss=118.7389, Acc=77.48%\n  Epoch 50/100: Loss=115.6161, Acc=79.19%\n  Epoch 60/100: Loss=113.8872, Acc=78.98%\n  Epoch 70/100: Loss=111.7509, Acc=79.06%\n  Epoch 80/100: Loss=108.1228, Acc=80.47%\n  Epoch 90/100: Loss=106.5657, Acc=81.02%\n  Epoch 100/100: Loss=104.1883, Acc=80.88%\n  Final training accuracy: 80.88%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.5510\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=137.8374, Acc=72.58%\n  Epoch 20/100: Loss=129.9914, Acc=74.67%\n  Epoch 30/100: Loss=124.6189, Acc=75.52%\n  Epoch 40/100: Loss=119.8307, Acc=77.78%\n  Epoch 50/100: Loss=115.7878, Acc=77.86%\n  Epoch 60/100: Loss=113.7347, Acc=78.83%\n  Epoch 70/100: Loss=110.2622, Acc=79.83%\n  Epoch 80/100: Loss=107.0852, Acc=80.08%\n  Epoch 90/100: Loss=105.9100, Acc=80.49%\n  Epoch 100/100: Loss=103.1658, Acc=81.36%\n  Final training accuracy: 81.36%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=1.0000 | Acc=1.0000\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.4 with F1=1.0000\n  Testing...\n  Validation loss: 0.6130\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.5546, Acc=69.77%\n  Epoch 20/100: Loss=134.0061, Acc=73.65%\n  Epoch 30/100: Loss=130.2713, Acc=73.92%\n  Epoch 40/100: Loss=127.9793, Acc=75.80%\n  Epoch 50/100: Loss=123.8896, Acc=76.11%\n  Epoch 60/100: Loss=122.6816, Acc=76.61%\n  Epoch 70/100: Loss=119.2219, Acc=77.20%\n  Epoch 80/100: Loss=116.1523, Acc=78.52%\n  Epoch 90/100: Loss=111.7667, Acc=79.46%\n  Epoch 100/100: Loss=110.9990, Acc=79.46%\n  Final training accuracy: 79.46%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.2293\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.9976, Acc=72.26%\n  Epoch 20/100: Loss=127.2694, Acc=75.12%\n  Epoch 30/100: Loss=120.4945, Acc=76.53%\n  Epoch 40/100: Loss=117.4175, Acc=77.20%\n  Epoch 50/100: Loss=114.2596, Acc=78.32%\n  Epoch 60/100: Loss=111.8143, Acc=79.08%\n  Epoch 70/100: Loss=109.8755, Acc=79.37%\n  Epoch 80/100: Loss=106.6273, Acc=80.32%\n  Epoch 90/100: Loss=103.9940, Acc=80.42%\n  Epoch 100/100: Loss=101.9537, Acc=81.26%\n  Final training accuracy: 81.26%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.5687\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.7353, Acc=72.43%\n  Epoch 20/100: Loss=127.2304, Acc=75.75%\n  Epoch 30/100: Loss=121.8536, Acc=76.98%\n  Epoch 40/100: Loss=120.0961, Acc=77.25%\n  Epoch 50/100: Loss=116.6131, Acc=78.26%\n  Epoch 60/100: Loss=111.7730, Acc=79.44%\n  Epoch 70/100: Loss=111.9603, Acc=79.56%\n  Epoch 80/100: Loss=108.0797, Acc=80.19%\n  Epoch 90/100: Loss=107.0293, Acc=80.70%\n  Epoch 100/100: Loss=103.2865, Acc=81.69%\n  Final training accuracy: 81.69%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 0.5571\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=143.1198, Acc=71.15%\n  Epoch 20/100: Loss=132.6822, Acc=74.13%\n  Epoch 30/100: Loss=125.7051, Acc=75.71%\n  Epoch 40/100: Loss=121.1812, Acc=77.01%\n  Epoch 50/100: Loss=115.1854, Acc=78.80%\n  Epoch 60/100: Loss=111.2801, Acc=79.02%\n  Epoch 70/100: Loss=108.3494, Acc=80.24%\n  Epoch 80/100: Loss=105.7358, Acc=80.70%\n  Epoch 90/100: Loss=102.6932, Acc=81.73%\n  Epoch 100/100: Loss=99.8998, Acc=81.89%\n  Final training accuracy: 81.89%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.6482\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n  Repetition 4 Results:\n  Mean accuracy: 78.33% ± 20.45%\n  Mean F1: 0.7786 ± 0.2072\n\n================================================================================\nREPETITION 5/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.2275, Acc=69.65%\n  Epoch 20/100: Loss=130.5863, Acc=72.43%\n  Epoch 30/100: Loss=126.8713, Acc=74.16%\n  Epoch 40/100: Loss=122.0319, Acc=75.40%\n  Epoch 50/100: Loss=119.0263, Acc=75.88%\n  Epoch 60/100: Loss=115.1546, Acc=76.92%\n  Epoch 70/100: Loss=112.2212, Acc=77.57%\n  Epoch 80/100: Loss=105.4598, Acc=79.75%\n  Epoch 90/100: Loss=104.2814, Acc=79.80%\n  Epoch 100/100: Loss=99.2595, Acc=80.91%\n  Final training accuracy: 80.91%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8000 | Acc=0.8163\n    [Threshold 0.3] -> F1=0.8711 | Acc=0.8776\n    [Threshold 0.4] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.5566\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.4545, Acc=71.05%\n  Epoch 20/100: Loss=130.2715, Acc=75.05%\n  Epoch 30/100: Loss=124.9783, Acc=76.25%\n  Epoch 40/100: Loss=120.5621, Acc=77.26%\n  Epoch 50/100: Loss=115.9742, Acc=78.17%\n  Epoch 60/100: Loss=113.9008, Acc=77.84%\n  Epoch 70/100: Loss=109.3999, Acc=80.26%\n  Epoch 80/100: Loss=107.2698, Acc=80.13%\n  Epoch 90/100: Loss=105.4912, Acc=80.69%\n  Epoch 100/100: Loss=104.2122, Acc=81.10%\n  Final training accuracy: 81.10%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9588 | Acc=0.9592\n    [Best Threshold] = 0.4 with F1=0.9790\n  Testing...\n  Validation loss: 0.6898\n  Validation accuracy: 66.67%\n  Validation F1: 0.6250\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.6875, Acc=70.19%\n  Epoch 20/100: Loss=130.6069, Acc=74.36%\n  Epoch 30/100: Loss=122.3520, Acc=76.50%\n  Epoch 40/100: Loss=117.9109, Acc=77.50%\n  Epoch 50/100: Loss=114.1615, Acc=78.64%\n  Epoch 60/100: Loss=112.4082, Acc=79.68%\n  Epoch 70/100: Loss=108.7637, Acc=80.11%\n  Epoch 80/100: Loss=106.3683, Acc=80.41%\n  Epoch 90/100: Loss=104.1792, Acc=81.23%\n  Epoch 100/100: Loss=101.6575, Acc=82.33%\n  Final training accuracy: 82.33%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.6397\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.6450, Acc=71.67%\n  Epoch 20/100: Loss=131.6297, Acc=74.19%\n  Epoch 30/100: Loss=125.3317, Acc=75.31%\n  Epoch 40/100: Loss=121.9320, Acc=76.61%\n  Epoch 50/100: Loss=117.5689, Acc=77.85%\n  Epoch 60/100: Loss=115.5299, Acc=78.01%\n  Epoch 70/100: Loss=112.5158, Acc=78.70%\n  Epoch 80/100: Loss=110.6104, Acc=79.29%\n  Epoch 90/100: Loss=107.4169, Acc=79.41%\n  Epoch 100/100: Loss=106.2878, Acc=80.13%\n  Final training accuracy: 80.13%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.4946\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.9356, Acc=73.44%\n  Epoch 20/100: Loss=127.8919, Acc=75.34%\n  Epoch 30/100: Loss=123.2963, Acc=76.88%\n  Epoch 40/100: Loss=119.7063, Acc=77.70%\n  Epoch 50/100: Loss=115.5597, Acc=78.82%\n  Epoch 60/100: Loss=113.6884, Acc=78.98%\n  Epoch 70/100: Loss=109.9883, Acc=80.56%\n  Epoch 80/100: Loss=105.2842, Acc=80.96%\n  Epoch 90/100: Loss=104.7225, Acc=81.53%\n  Epoch 100/100: Loss=101.8626, Acc=81.74%\n  Final training accuracy: 81.74%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.9851\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=132.6967, Acc=74.67%\n  Epoch 20/100: Loss=122.8151, Acc=77.17%\n  Epoch 30/100: Loss=119.3047, Acc=78.13%\n  Epoch 40/100: Loss=115.3545, Acc=78.64%\n  Epoch 50/100: Loss=112.5632, Acc=79.61%\n  Epoch 60/100: Loss=109.8475, Acc=80.21%\n  Epoch 70/100: Loss=107.1558, Acc=80.94%\n  Epoch 80/100: Loss=105.3228, Acc=81.65%\n  Epoch 90/100: Loss=103.0896, Acc=81.63%\n  Epoch 100/100: Loss=103.1644, Acc=81.76%\n  Final training accuracy: 81.76%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.7305\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.3096, Acc=72.30%\n  Epoch 20/100: Loss=122.5779, Acc=75.69%\n  Epoch 30/100: Loss=115.6359, Acc=77.71%\n  Epoch 40/100: Loss=111.6539, Acc=78.34%\n  Epoch 50/100: Loss=107.8727, Acc=79.69%\n  Epoch 60/100: Loss=105.3025, Acc=80.58%\n  Epoch 70/100: Loss=102.3482, Acc=80.84%\n  Epoch 80/100: Loss=100.1593, Acc=81.25%\n  Epoch 90/100: Loss=99.4291, Acc=81.12%\n  Epoch 100/100: Loss=96.6317, Acc=82.38%\n  Final training accuracy: 82.38%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8022 | Acc=0.8200\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9594\n  Testing...\n  Validation loss: 0.6869\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.2963, Acc=69.38%\n  Epoch 20/100: Loss=133.2918, Acc=73.00%\n  Epoch 30/100: Loss=126.2495, Acc=75.66%\n  Epoch 40/100: Loss=121.6369, Acc=76.84%\n  Epoch 50/100: Loss=117.4350, Acc=77.36%\n  Epoch 60/100: Loss=115.1316, Acc=78.35%\n  Epoch 70/100: Loss=112.3784, Acc=79.09%\n  Epoch 80/100: Loss=108.9167, Acc=79.64%\n  Epoch 90/100: Loss=105.9378, Acc=80.42%\n  Epoch 100/100: Loss=104.8346, Acc=81.17%\n  Final training accuracy: 81.17%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8264 | Acc=0.8400\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.5070\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.3659, Acc=70.95%\n  Epoch 20/100: Loss=135.1548, Acc=72.31%\n  Epoch 30/100: Loss=128.6024, Acc=74.87%\n  Epoch 40/100: Loss=122.0418, Acc=75.75%\n  Epoch 50/100: Loss=121.7081, Acc=76.80%\n  Epoch 60/100: Loss=116.7237, Acc=78.13%\n  Epoch 70/100: Loss=114.5092, Acc=78.59%\n  Epoch 80/100: Loss=110.9037, Acc=79.03%\n  Epoch 90/100: Loss=108.6717, Acc=79.97%\n  Epoch 100/100: Loss=106.3163, Acc=80.52%\n  Final training accuracy: 80.52%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.8211\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.9831, Acc=72.46%\n  Epoch 20/100: Loss=127.8303, Acc=75.20%\n  Epoch 30/100: Loss=122.4545, Acc=76.52%\n  Epoch 40/100: Loss=119.4058, Acc=76.86%\n  Epoch 50/100: Loss=113.7255, Acc=78.84%\n  Epoch 60/100: Loss=110.9119, Acc=79.46%\n  Epoch 70/100: Loss=109.7962, Acc=79.66%\n  Epoch 80/100: Loss=105.9698, Acc=80.34%\n  Epoch 90/100: Loss=104.8415, Acc=80.96%\n  Epoch 100/100: Loss=102.5641, Acc=81.28%\n  Final training accuracy: 81.28%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.3] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.5890\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n  Repetition 5 Results:\n  Mean accuracy: 76.33% ± 11.00%\n  Mean F1: 0.7494 ± 0.1146\n\n================================================================================\nREPETITION 6/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=125.4416, Acc=75.17%\n  Epoch 20/100: Loss=117.7021, Acc=77.40%\n  Epoch 30/100: Loss=112.0036, Acc=78.54%\n  Epoch 40/100: Loss=109.5216, Acc=79.07%\n  Epoch 50/100: Loss=106.0703, Acc=80.19%\n  Epoch 60/100: Loss=104.7542, Acc=80.28%\n  Epoch 70/100: Loss=101.1653, Acc=81.24%\n  Epoch 80/100: Loss=98.8036, Acc=81.64%\n  Epoch 90/100: Loss=96.0678, Acc=82.26%\n  Epoch 100/100: Loss=96.3372, Acc=82.33%\n  Final training accuracy: 82.33%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8935 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9378 | Acc=0.9388\n    [Best Threshold] = 0.5 with F1=0.9378\n  Testing...\n  Validation loss: 1.0806\n  Validation accuracy: 50.00%\n  Validation F1: 0.4857\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.7666, Acc=70.14%\n  Epoch 20/100: Loss=136.1922, Acc=73.23%\n  Epoch 30/100: Loss=131.3378, Acc=74.09%\n  Epoch 40/100: Loss=127.1990, Acc=75.14%\n  Epoch 50/100: Loss=122.0952, Acc=76.18%\n  Epoch 60/100: Loss=118.2129, Acc=77.66%\n  Epoch 70/100: Loss=115.6549, Acc=78.11%\n  Epoch 80/100: Loss=112.1157, Acc=79.14%\n  Epoch 90/100: Loss=108.6404, Acc=79.77%\n  Epoch 100/100: Loss=105.7509, Acc=80.53%\n  Final training accuracy: 80.53%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.4689\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=137.2115, Acc=73.80%\n  Epoch 20/100: Loss=127.8082, Acc=76.65%\n  Epoch 30/100: Loss=124.5768, Acc=77.40%\n  Epoch 40/100: Loss=119.9583, Acc=78.09%\n  Epoch 50/100: Loss=115.2154, Acc=79.21%\n  Epoch 60/100: Loss=112.6888, Acc=79.88%\n  Epoch 70/100: Loss=110.1470, Acc=80.02%\n  Epoch 80/100: Loss=107.8269, Acc=80.71%\n  Epoch 90/100: Loss=105.4659, Acc=81.20%\n  Epoch 100/100: Loss=103.6212, Acc=81.55%\n  Final training accuracy: 81.55%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9578 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9578\n  Testing...\n  Validation loss: 0.5071\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.0240, Acc=71.37%\n  Epoch 20/100: Loss=130.6579, Acc=74.53%\n  Epoch 30/100: Loss=126.9140, Acc=75.20%\n  Epoch 40/100: Loss=120.2863, Acc=77.34%\n  Epoch 50/100: Loss=117.6997, Acc=78.20%\n  Epoch 60/100: Loss=116.6380, Acc=77.82%\n  Epoch 70/100: Loss=113.3604, Acc=79.08%\n  Epoch 80/100: Loss=110.1266, Acc=80.04%\n  Epoch 90/100: Loss=108.7248, Acc=80.62%\n  Epoch 100/100: Loss=106.0585, Acc=80.58%\n  Final training accuracy: 80.58%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.4799\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.7125, Acc=72.59%\n  Epoch 20/100: Loss=125.1850, Acc=74.78%\n  Epoch 30/100: Loss=120.7424, Acc=75.88%\n  Epoch 40/100: Loss=116.1789, Acc=77.68%\n  Epoch 50/100: Loss=110.2924, Acc=78.82%\n  Epoch 60/100: Loss=108.9987, Acc=79.31%\n  Epoch 70/100: Loss=103.8887, Acc=80.76%\n  Epoch 80/100: Loss=101.1496, Acc=81.53%\n  Epoch 90/100: Loss=97.0029, Acc=82.20%\n  Epoch 100/100: Loss=95.4219, Acc=82.32%\n  Final training accuracy: 82.32%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=1.0000 | Acc=1.0000\n    [Threshold 0.5] -> F1=1.0000 | Acc=1.0000\n    [Best Threshold] = 0.4 with F1=1.0000\n  Testing...\n  Validation loss: 0.7192\n  Validation accuracy: 66.67%\n  Validation F1: 0.6250\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.0347, Acc=71.20%\n  Epoch 20/100: Loss=128.6299, Acc=74.70%\n  Epoch 30/100: Loss=124.0794, Acc=75.78%\n  Epoch 40/100: Loss=119.3300, Acc=76.93%\n  Epoch 50/100: Loss=116.1778, Acc=78.29%\n  Epoch 60/100: Loss=114.5366, Acc=78.45%\n  Epoch 70/100: Loss=109.9965, Acc=78.93%\n  Epoch 80/100: Loss=110.3052, Acc=79.31%\n  Epoch 90/100: Loss=106.9806, Acc=80.60%\n  Epoch 100/100: Loss=104.8362, Acc=80.76%\n  Final training accuracy: 80.76%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9388 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9594 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9199 | Acc=0.9200\n    [Best Threshold] = 0.4 with F1=0.9594\n  Testing...\n  Validation loss: 1.0228\n  Validation accuracy: 40.00%\n  Validation F1: 0.4000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.4299, Acc=71.40%\n  Epoch 20/100: Loss=130.5130, Acc=74.17%\n  Epoch 30/100: Loss=126.5601, Acc=75.57%\n  Epoch 40/100: Loss=122.4617, Acc=76.45%\n  Epoch 50/100: Loss=119.5129, Acc=77.18%\n  Epoch 60/100: Loss=116.0172, Acc=77.73%\n  Epoch 70/100: Loss=115.0376, Acc=78.46%\n  Epoch 80/100: Loss=110.5634, Acc=79.83%\n  Epoch 90/100: Loss=109.6922, Acc=79.92%\n  Epoch 100/100: Loss=106.1095, Acc=80.70%\n  Final training accuracy: 80.70%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=1.0000 | Acc=1.0000\n    [Best Threshold] = 0.5 with F1=1.0000\n  Testing...\n  Validation loss: 0.7653\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.9253, Acc=72.25%\n  Epoch 20/100: Loss=130.3312, Acc=74.60%\n  Epoch 30/100: Loss=124.6910, Acc=76.42%\n  Epoch 40/100: Loss=121.2605, Acc=77.49%\n  Epoch 50/100: Loss=117.6938, Acc=78.24%\n  Epoch 60/100: Loss=114.1347, Acc=79.03%\n  Epoch 70/100: Loss=110.6784, Acc=80.10%\n  Epoch 80/100: Loss=108.1072, Acc=80.21%\n  Epoch 90/100: Loss=105.0380, Acc=80.81%\n  Epoch 100/100: Loss=101.3438, Acc=81.69%\n  Final training accuracy: 81.69%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 0.7172\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.6352, Acc=71.65%\n  Epoch 20/100: Loss=131.7248, Acc=73.48%\n  Epoch 30/100: Loss=124.4187, Acc=75.05%\n  Epoch 40/100: Loss=119.6511, Acc=76.91%\n  Epoch 50/100: Loss=115.3808, Acc=77.56%\n  Epoch 60/100: Loss=112.5569, Acc=78.12%\n  Epoch 70/100: Loss=110.1991, Acc=79.29%\n  Epoch 80/100: Loss=106.4230, Acc=79.68%\n  Epoch 90/100: Loss=104.9878, Acc=80.18%\n  Epoch 100/100: Loss=101.8901, Acc=81.00%\n  Final training accuracy: 81.00%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.7146\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.8400, Acc=71.60%\n  Epoch 20/100: Loss=137.6990, Acc=71.97%\n  Epoch 30/100: Loss=133.7900, Acc=73.47%\n  Epoch 40/100: Loss=130.1966, Acc=74.51%\n  Epoch 50/100: Loss=124.9530, Acc=75.60%\n  Epoch 60/100: Loss=121.5730, Acc=76.73%\n  Epoch 70/100: Loss=119.0114, Acc=77.08%\n  Epoch 80/100: Loss=115.2928, Acc=78.03%\n  Epoch 90/100: Loss=112.0188, Acc=79.06%\n  Epoch 100/100: Loss=108.9061, Acc=79.93%\n  Final training accuracy: 79.93%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.3186\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n  Repetition 6 Results:\n  Mean accuracy: 74.33% ± 18.92%\n  Mean F1: 0.7351 ± 0.1939\n\n================================================================================\nREPETITION 7/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.5714, Acc=70.57%\n  Epoch 20/100: Loss=131.2325, Acc=72.52%\n  Epoch 30/100: Loss=124.1562, Acc=74.86%\n  Epoch 40/100: Loss=119.4464, Acc=76.03%\n  Epoch 50/100: Loss=115.9401, Acc=77.05%\n  Epoch 60/100: Loss=112.8541, Acc=77.75%\n  Epoch 70/100: Loss=110.5872, Acc=78.36%\n  Epoch 80/100: Loss=108.8196, Acc=79.12%\n  Epoch 90/100: Loss=105.9433, Acc=79.88%\n  Epoch 100/100: Loss=102.2306, Acc=80.80%\n  Final training accuracy: 80.80%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.3] -> F1=0.9583 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9795 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9387 | Acc=0.9388\n    [Best Threshold] = 0.4 with F1=0.9795\n  Testing...\n  Validation loss: 0.6332\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=147.1652, Acc=68.42%\n  Epoch 20/100: Loss=127.8791, Acc=73.89%\n  Epoch 30/100: Loss=122.8572, Acc=75.41%\n  Epoch 40/100: Loss=119.0330, Acc=76.07%\n  Epoch 50/100: Loss=115.0877, Acc=77.42%\n  Epoch 60/100: Loss=110.7786, Acc=78.30%\n  Epoch 70/100: Loss=108.5203, Acc=79.00%\n  Epoch 80/100: Loss=105.2707, Acc=79.78%\n  Epoch 90/100: Loss=105.2593, Acc=79.79%\n  Epoch 100/100: Loss=101.7375, Acc=80.52%\n  Final training accuracy: 80.52%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.6223\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=147.9427, Acc=69.24%\n  Epoch 20/100: Loss=136.6935, Acc=72.49%\n  Epoch 30/100: Loss=130.5214, Acc=74.50%\n  Epoch 40/100: Loss=125.9411, Acc=75.93%\n  Epoch 50/100: Loss=122.5690, Acc=76.43%\n  Epoch 60/100: Loss=118.0356, Acc=78.02%\n  Epoch 70/100: Loss=114.1892, Acc=78.84%\n  Epoch 80/100: Loss=112.6629, Acc=78.96%\n  Epoch 90/100: Loss=109.2363, Acc=80.37%\n  Epoch 100/100: Loss=107.1439, Acc=80.69%\n  Final training accuracy: 80.69%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9378 | Acc=0.9388\n    [Best Threshold] = 0.4 with F1=0.9578\n  Testing...\n  Validation loss: 0.4127\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.1679, Acc=70.99%\n  Epoch 20/100: Loss=134.3180, Acc=73.29%\n  Epoch 30/100: Loss=129.0068, Acc=74.29%\n  Epoch 40/100: Loss=125.5818, Acc=75.77%\n  Epoch 50/100: Loss=121.9347, Acc=76.57%\n  Epoch 60/100: Loss=117.4295, Acc=77.57%\n  Epoch 70/100: Loss=116.0795, Acc=77.83%\n  Epoch 80/100: Loss=112.1508, Acc=78.82%\n  Epoch 90/100: Loss=110.4396, Acc=79.35%\n  Epoch 100/100: Loss=107.7291, Acc=79.96%\n  Final training accuracy: 79.96%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9583 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.6550\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=132.2015, Acc=74.67%\n  Epoch 20/100: Loss=119.8420, Acc=77.49%\n  Epoch 30/100: Loss=113.0122, Acc=79.92%\n  Epoch 40/100: Loss=109.6250, Acc=80.17%\n  Epoch 50/100: Loss=108.3158, Acc=80.40%\n  Epoch 60/100: Loss=102.8775, Acc=81.93%\n  Epoch 70/100: Loss=101.3999, Acc=82.53%\n  Epoch 80/100: Loss=99.1113, Acc=82.97%\n  Epoch 90/100: Loss=97.9834, Acc=82.67%\n  Epoch 100/100: Loss=95.5471, Acc=83.26%\n  Final training accuracy: 83.26%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.8097\n  Validation accuracy: 50.00%\n  Validation F1: 0.4857\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=143.8044, Acc=69.11%\n  Epoch 20/100: Loss=134.3699, Acc=72.37%\n  Epoch 30/100: Loss=127.6429, Acc=74.12%\n  Epoch 40/100: Loss=122.9452, Acc=75.80%\n  Epoch 50/100: Loss=119.9715, Acc=76.87%\n  Epoch 60/100: Loss=115.9804, Acc=78.07%\n  Epoch 70/100: Loss=113.2963, Acc=78.83%\n  Epoch 80/100: Loss=111.3293, Acc=79.06%\n  Epoch 90/100: Loss=109.6476, Acc=79.18%\n  Epoch 100/100: Loss=105.1860, Acc=80.46%\n  Final training accuracy: 80.46%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9394 | Acc=0.9400\n    [Best Threshold] = 0.4 with F1=0.9589\n  Testing...\n  Validation loss: 0.3821\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=140.2813, Acc=72.68%\n  Epoch 20/100: Loss=129.1084, Acc=75.18%\n  Epoch 30/100: Loss=124.6625, Acc=76.25%\n  Epoch 40/100: Loss=120.5300, Acc=77.61%\n  Epoch 50/100: Loss=118.7130, Acc=78.01%\n  Epoch 60/100: Loss=114.2409, Acc=79.12%\n  Epoch 70/100: Loss=110.8709, Acc=80.12%\n  Epoch 80/100: Loss=109.7776, Acc=80.33%\n  Epoch 90/100: Loss=107.9613, Acc=80.66%\n  Epoch 100/100: Loss=103.9212, Acc=81.73%\n  Final training accuracy: 81.73%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9594\n  Testing...\n  Validation loss: 0.6109\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.7036, Acc=71.81%\n  Epoch 20/100: Loss=131.9965, Acc=74.27%\n  Epoch 30/100: Loss=128.3363, Acc=75.22%\n  Epoch 40/100: Loss=123.4655, Acc=76.86%\n  Epoch 50/100: Loss=120.3451, Acc=77.25%\n  Epoch 60/100: Loss=117.9486, Acc=78.16%\n  Epoch 70/100: Loss=114.1724, Acc=78.45%\n  Epoch 80/100: Loss=111.8279, Acc=79.24%\n  Epoch 90/100: Loss=109.9137, Acc=80.06%\n  Epoch 100/100: Loss=107.6188, Acc=80.41%\n  Final training accuracy: 80.41%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.3681\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=134.9484, Acc=73.05%\n  Epoch 20/100: Loss=125.6818, Acc=75.41%\n  Epoch 30/100: Loss=120.4611, Acc=76.87%\n  Epoch 40/100: Loss=117.4335, Acc=78.19%\n  Epoch 50/100: Loss=112.5258, Acc=79.32%\n  Epoch 60/100: Loss=111.7863, Acc=79.07%\n  Epoch 70/100: Loss=108.1169, Acc=80.14%\n  Epoch 80/100: Loss=105.4635, Acc=80.89%\n  Epoch 90/100: Loss=103.4000, Acc=81.56%\n  Epoch 100/100: Loss=101.8769, Acc=81.95%\n  Final training accuracy: 81.95%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9594 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 1.4070\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.2858, Acc=72.88%\n  Epoch 20/100: Loss=125.7052, Acc=76.99%\n  Epoch 30/100: Loss=117.1827, Acc=78.80%\n  Epoch 40/100: Loss=113.8066, Acc=79.85%\n  Epoch 50/100: Loss=107.4426, Acc=81.23%\n  Epoch 60/100: Loss=104.6951, Acc=82.25%\n  Epoch 70/100: Loss=101.8891, Acc=82.81%\n  Epoch 80/100: Loss=98.5022, Acc=82.98%\n  Epoch 90/100: Loss=95.1035, Acc=83.85%\n  Epoch 100/100: Loss=92.7776, Acc=84.23%\n  Final training accuracy: 84.23%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 1.1583\n  Validation accuracy: 20.00%\n  Validation F1: 0.1667\n\n  Repetition 7 Results:\n  Mean accuracy: 78.00% ± 25.48%\n  Mean F1: 0.7721 ± 0.2649\n\n================================================================================\nREPETITION 8/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=130.6003, Acc=73.21%\n  Epoch 20/100: Loss=121.5836, Acc=75.86%\n  Epoch 30/100: Loss=116.3150, Acc=77.01%\n  Epoch 40/100: Loss=111.2050, Acc=78.74%\n  Epoch 50/100: Loss=109.4143, Acc=79.83%\n  Epoch 60/100: Loss=105.1471, Acc=81.05%\n  Epoch 70/100: Loss=103.3848, Acc=80.57%\n  Epoch 80/100: Loss=101.1669, Acc=81.15%\n  Epoch 90/100: Loss=98.3996, Acc=81.63%\n  Epoch 100/100: Loss=96.8957, Acc=82.03%\n  Final training accuracy: 82.03%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8711 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.8935 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.8604\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.7226, Acc=71.64%\n  Epoch 20/100: Loss=130.5653, Acc=74.68%\n  Epoch 30/100: Loss=126.3390, Acc=75.18%\n  Epoch 40/100: Loss=122.3948, Acc=76.26%\n  Epoch 50/100: Loss=119.7275, Acc=77.01%\n  Epoch 60/100: Loss=118.1327, Acc=77.09%\n  Epoch 70/100: Loss=114.3239, Acc=78.07%\n  Epoch 80/100: Loss=113.9193, Acc=78.61%\n  Epoch 90/100: Loss=111.2208, Acc=79.34%\n  Epoch 100/100: Loss=110.1936, Acc=79.30%\n  Final training accuracy: 79.30%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8199 | Acc=0.8367\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.5214\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.8601, Acc=72.04%\n  Epoch 20/100: Loss=131.3499, Acc=73.89%\n  Epoch 30/100: Loss=125.2946, Acc=76.50%\n  Epoch 40/100: Loss=120.6130, Acc=77.33%\n  Epoch 50/100: Loss=114.5440, Acc=78.91%\n  Epoch 60/100: Loss=112.4632, Acc=79.36%\n  Epoch 70/100: Loss=110.0643, Acc=79.99%\n  Epoch 80/100: Loss=108.4596, Acc=80.28%\n  Epoch 90/100: Loss=106.0213, Acc=80.89%\n  Epoch 100/100: Loss=103.5659, Acc=81.41%\n  Final training accuracy: 81.41%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.5539\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.4621, Acc=72.42%\n  Epoch 20/100: Loss=128.6427, Acc=74.28%\n  Epoch 30/100: Loss=122.9443, Acc=76.50%\n  Epoch 40/100: Loss=118.1118, Acc=77.50%\n  Epoch 50/100: Loss=114.4482, Acc=78.19%\n  Epoch 60/100: Loss=110.5779, Acc=78.80%\n  Epoch 70/100: Loss=107.0881, Acc=80.19%\n  Epoch 80/100: Loss=104.1763, Acc=80.72%\n  Epoch 90/100: Loss=102.3960, Acc=81.07%\n  Epoch 100/100: Loss=101.1659, Acc=81.35%\n  Final training accuracy: 81.35%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9175 | Acc=0.9184\n    [Best Threshold] = 0.4 with F1=0.9790\n  Testing...\n  Validation loss: 1.2138\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=143.6282, Acc=69.98%\n  Epoch 20/100: Loss=135.1881, Acc=72.12%\n  Epoch 30/100: Loss=128.6020, Acc=74.51%\n  Epoch 40/100: Loss=123.7553, Acc=75.64%\n  Epoch 50/100: Loss=119.1559, Acc=76.80%\n  Epoch 60/100: Loss=116.0258, Acc=77.96%\n  Epoch 70/100: Loss=112.3188, Acc=78.92%\n  Epoch 80/100: Loss=111.1717, Acc=79.27%\n  Epoch 90/100: Loss=107.9257, Acc=80.07%\n  Epoch 100/100: Loss=107.3811, Acc=80.13%\n  Final training accuracy: 80.13%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8199 | Acc=0.8367\n    [Threshold 0.3] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9790 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9790\n  Testing...\n  Validation loss: 0.5953\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.8134, Acc=73.03%\n  Epoch 20/100: Loss=125.6159, Acc=76.06%\n  Epoch 30/100: Loss=118.6909, Acc=77.41%\n  Epoch 40/100: Loss=113.5303, Acc=78.64%\n  Epoch 50/100: Loss=110.8635, Acc=79.12%\n  Epoch 60/100: Loss=106.9915, Acc=80.20%\n  Epoch 70/100: Loss=104.0061, Acc=80.63%\n  Epoch 80/100: Loss=100.1462, Acc=81.79%\n  Epoch 90/100: Loss=99.7576, Acc=82.41%\n  Epoch 100/100: Loss=95.9788, Acc=82.50%\n  Final training accuracy: 82.50%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.3] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 0.7316\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.6113, Acc=72.53%\n  Epoch 20/100: Loss=125.3455, Acc=75.52%\n  Epoch 30/100: Loss=120.8570, Acc=76.97%\n  Epoch 40/100: Loss=116.6342, Acc=77.92%\n  Epoch 50/100: Loss=113.4053, Acc=79.34%\n  Epoch 60/100: Loss=108.6357, Acc=80.43%\n  Epoch 70/100: Loss=106.2365, Acc=80.53%\n  Epoch 80/100: Loss=104.6986, Acc=80.90%\n  Epoch 90/100: Loss=102.4603, Acc=81.16%\n  Epoch 100/100: Loss=100.3623, Acc=82.15%\n  Final training accuracy: 82.15%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9594 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.6372\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.0609, Acc=72.15%\n  Epoch 20/100: Loss=131.3371, Acc=74.68%\n  Epoch 30/100: Loss=125.6335, Acc=76.81%\n  Epoch 40/100: Loss=120.2368, Acc=77.84%\n  Epoch 50/100: Loss=117.8552, Acc=78.04%\n  Epoch 60/100: Loss=115.2402, Acc=78.96%\n  Epoch 70/100: Loss=112.2771, Acc=79.62%\n  Epoch 80/100: Loss=108.7243, Acc=80.54%\n  Epoch 90/100: Loss=106.9991, Acc=80.48%\n  Epoch 100/100: Loss=105.2125, Acc=80.97%\n  Final training accuracy: 80.97%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9597 | Acc=0.9600\n    [Best Threshold] = 0.4 with F1=0.9796\n  Testing...\n  Validation loss: 0.5854\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.0427, Acc=73.07%\n  Epoch 20/100: Loss=127.5160, Acc=75.20%\n  Epoch 30/100: Loss=122.5128, Acc=76.15%\n  Epoch 40/100: Loss=118.6292, Acc=77.02%\n  Epoch 50/100: Loss=115.9837, Acc=78.22%\n  Epoch 60/100: Loss=113.0227, Acc=78.63%\n  Epoch 70/100: Loss=111.4167, Acc=78.95%\n  Epoch 80/100: Loss=105.7911, Acc=80.56%\n  Epoch 90/100: Loss=104.6956, Acc=80.76%\n  Epoch 100/100: Loss=102.4509, Acc=80.94%\n  Final training accuracy: 80.94%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.5] -> F1=0.9589 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9589\n  Testing...\n  Validation loss: 0.4532\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.4499, Acc=72.00%\n  Epoch 20/100: Loss=128.5539, Acc=75.05%\n  Epoch 30/100: Loss=122.9854, Acc=76.27%\n  Epoch 40/100: Loss=120.4725, Acc=77.03%\n  Epoch 50/100: Loss=119.2540, Acc=77.35%\n  Epoch 60/100: Loss=115.5001, Acc=77.91%\n  Epoch 70/100: Loss=114.0294, Acc=78.37%\n  Epoch 80/100: Loss=111.6132, Acc=79.21%\n  Epoch 90/100: Loss=107.3506, Acc=79.94%\n  Epoch 100/100: Loss=105.6482, Acc=80.44%\n  Final training accuracy: 80.44%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.5651\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n  Repetition 8 Results:\n  Mean accuracy: 79.67% ± 13.45%\n  Mean F1: 0.7881 ± 0.1393\n\n================================================================================\nREPETITION 9/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=124.9621, Acc=75.77%\n  Epoch 20/100: Loss=118.5401, Acc=77.21%\n  Epoch 30/100: Loss=115.1885, Acc=78.33%\n  Epoch 40/100: Loss=109.9168, Acc=79.03%\n  Epoch 50/100: Loss=107.4850, Acc=80.11%\n  Epoch 60/100: Loss=105.3401, Acc=80.86%\n  Epoch 70/100: Loss=104.7469, Acc=80.57%\n  Epoch 80/100: Loss=99.1200, Acc=82.18%\n  Epoch 90/100: Loss=97.0090, Acc=82.33%\n  Epoch 100/100: Loss=96.3302, Acc=81.94%\n  Final training accuracy: 81.94%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8935 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9155 | Acc=0.9184\n    [Threshold 0.4] -> F1=0.9793 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9588 | Acc=0.9592\n    [Best Threshold] = 0.4 with F1=0.9793\n  Testing...\n  Validation loss: 0.8750\n  Validation accuracy: 50.00%\n  Validation F1: 0.3333\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=132.1759, Acc=74.41%\n  Epoch 20/100: Loss=117.7255, Acc=78.13%\n  Epoch 30/100: Loss=112.5195, Acc=79.79%\n  Epoch 40/100: Loss=108.5751, Acc=80.05%\n  Epoch 50/100: Loss=106.4773, Acc=80.63%\n  Epoch 60/100: Loss=102.7077, Acc=81.73%\n  Epoch 70/100: Loss=99.0845, Acc=82.50%\n  Epoch 80/100: Loss=97.0444, Acc=82.72%\n  Epoch 90/100: Loss=95.7210, Acc=83.39%\n  Epoch 100/100: Loss=93.8245, Acc=83.81%\n  Final training accuracy: 83.81%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.9162\n  Validation accuracy: 50.00%\n  Validation F1: 0.4857\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=146.7194, Acc=69.07%\n  Epoch 20/100: Loss=136.2150, Acc=72.34%\n  Epoch 30/100: Loss=130.4180, Acc=74.50%\n  Epoch 40/100: Loss=125.1461, Acc=75.45%\n  Epoch 50/100: Loss=123.3178, Acc=76.23%\n  Epoch 60/100: Loss=119.9800, Acc=77.37%\n  Epoch 70/100: Loss=116.6172, Acc=78.06%\n  Epoch 80/100: Loss=114.0949, Acc=78.80%\n  Epoch 90/100: Loss=111.5840, Acc=79.12%\n  Epoch 100/100: Loss=109.5573, Acc=79.82%\n  Final training accuracy: 79.82%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9583 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9384 | Acc=0.9388\n    [Best Threshold] = 0.4 with F1=0.9583\n  Testing...\n  Validation loss: 0.5396\n  Validation accuracy: 66.67%\n  Validation F1: 0.6250\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.8951, Acc=71.53%\n  Epoch 20/100: Loss=132.7393, Acc=73.66%\n  Epoch 30/100: Loss=126.8225, Acc=75.41%\n  Epoch 40/100: Loss=120.2393, Acc=76.86%\n  Epoch 50/100: Loss=117.4337, Acc=77.80%\n  Epoch 60/100: Loss=113.5774, Acc=78.87%\n  Epoch 70/100: Loss=110.5282, Acc=79.43%\n  Epoch 80/100: Loss=105.9064, Acc=80.59%\n  Epoch 90/100: Loss=104.2859, Acc=81.18%\n  Epoch 100/100: Loss=100.3778, Acc=81.72%\n  Final training accuracy: 81.72%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.5] -> F1=0.9583 | Acc=0.9592\n    [Best Threshold] = 0.5 with F1=0.9583\n  Testing...\n  Validation loss: 0.5297\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=135.1119, Acc=72.54%\n  Epoch 20/100: Loss=124.7657, Acc=76.07%\n  Epoch 30/100: Loss=119.9573, Acc=76.96%\n  Epoch 40/100: Loss=114.9424, Acc=77.81%\n  Epoch 50/100: Loss=111.1903, Acc=79.28%\n  Epoch 60/100: Loss=108.8361, Acc=79.13%\n  Epoch 70/100: Loss=105.9767, Acc=80.25%\n  Epoch 80/100: Loss=104.3452, Acc=80.65%\n  Epoch 90/100: Loss=100.4553, Acc=81.17%\n  Epoch 100/100: Loss=100.0694, Acc=81.28%\n  Final training accuracy: 81.28%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.6520\n  Validation accuracy: 83.33%\n  Validation F1: 0.8286\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.2983, Acc=72.75%\n  Epoch 20/100: Loss=125.1466, Acc=75.80%\n  Epoch 30/100: Loss=120.4844, Acc=77.49%\n  Epoch 40/100: Loss=116.8310, Acc=78.29%\n  Epoch 50/100: Loss=114.1468, Acc=78.71%\n  Epoch 60/100: Loss=111.5198, Acc=79.66%\n  Epoch 70/100: Loss=107.1127, Acc=80.88%\n  Epoch 80/100: Loss=104.2537, Acc=81.07%\n  Epoch 90/100: Loss=101.7329, Acc=81.89%\n  Epoch 100/100: Loss=98.5889, Acc=82.25%\n  Final training accuracy: 82.25%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8264 | Acc=0.8400\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 0.6869\n  Validation accuracy: 80.00%\n  Validation F1: 0.7619\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.5208, Acc=71.33%\n  Epoch 20/100: Loss=133.6076, Acc=74.05%\n  Epoch 30/100: Loss=129.5530, Acc=74.50%\n  Epoch 40/100: Loss=126.0761, Acc=75.89%\n  Epoch 50/100: Loss=120.5615, Acc=77.11%\n  Epoch 60/100: Loss=119.7371, Acc=77.08%\n  Epoch 70/100: Loss=116.3088, Acc=77.83%\n  Epoch 80/100: Loss=114.0644, Acc=78.30%\n  Epoch 90/100: Loss=112.7769, Acc=79.30%\n  Epoch 100/100: Loss=108.9372, Acc=80.41%\n  Final training accuracy: 80.41%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9594 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9594\n  Testing...\n  Validation loss: 0.3348\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.4252, Acc=71.43%\n  Epoch 20/100: Loss=127.8629, Acc=74.59%\n  Epoch 30/100: Loss=120.5432, Acc=76.38%\n  Epoch 40/100: Loss=115.3298, Acc=77.83%\n  Epoch 50/100: Loss=111.6866, Acc=78.40%\n  Epoch 60/100: Loss=108.9332, Acc=79.15%\n  Epoch 70/100: Loss=105.3444, Acc=80.13%\n  Epoch 80/100: Loss=104.2241, Acc=80.12%\n  Epoch 90/100: Loss=101.8225, Acc=81.02%\n  Epoch 100/100: Loss=101.2716, Acc=80.80%\n  Final training accuracy: 80.80%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8022 | Acc=0.8200\n    [Threshold 0.3] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.4] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.5] -> F1=0.9589 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9589\n  Testing...\n  Validation loss: 1.0508\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=146.5389, Acc=70.65%\n  Epoch 20/100: Loss=139.1769, Acc=72.37%\n  Epoch 30/100: Loss=133.0492, Acc=73.42%\n  Epoch 40/100: Loss=126.9971, Acc=74.61%\n  Epoch 50/100: Loss=122.0176, Acc=76.71%\n  Epoch 60/100: Loss=119.0108, Acc=77.00%\n  Epoch 70/100: Loss=118.1269, Acc=77.40%\n  Epoch 80/100: Loss=114.5749, Acc=78.56%\n  Epoch 90/100: Loss=113.0626, Acc=79.28%\n  Epoch 100/100: Loss=109.5464, Acc=79.90%\n  Final training accuracy: 79.90%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.6733\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.0627, Acc=70.54%\n  Epoch 20/100: Loss=135.7827, Acc=72.73%\n  Epoch 30/100: Loss=130.0669, Acc=74.83%\n  Epoch 40/100: Loss=125.1571, Acc=75.53%\n  Epoch 50/100: Loss=121.2352, Acc=76.94%\n  Epoch 60/100: Loss=120.3635, Acc=77.09%\n  Epoch 70/100: Loss=116.0701, Acc=78.03%\n  Epoch 80/100: Loss=113.8149, Acc=78.67%\n  Epoch 90/100: Loss=110.4009, Acc=79.18%\n  Epoch 100/100: Loss=106.6697, Acc=79.95%\n  Final training accuracy: 79.95%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9597 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9597\n  Testing...\n  Validation loss: 0.3743\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n  Repetition 9 Results:\n  Mean accuracy: 79.00% ± 17.83%\n  Mean F1: 0.7635 ± 0.2136\n\n================================================================================\nREPETITION 10/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=136.7956, Acc=71.93%\n  Epoch 20/100: Loss=128.1269, Acc=74.34%\n  Epoch 30/100: Loss=124.2232, Acc=75.23%\n  Epoch 40/100: Loss=119.9078, Acc=76.96%\n  Epoch 50/100: Loss=117.6759, Acc=77.40%\n  Epoch 60/100: Loss=114.7727, Acc=77.85%\n  Epoch 70/100: Loss=113.2212, Acc=78.06%\n  Epoch 80/100: Loss=110.5791, Acc=79.05%\n  Epoch 90/100: Loss=107.8081, Acc=79.34%\n  Epoch 100/100: Loss=105.9438, Acc=80.01%\n  Final training accuracy: 80.01%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8000 | Acc=0.8163\n    [Threshold 0.3] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.3535\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=132.3087, Acc=72.53%\n  Epoch 20/100: Loss=119.4127, Acc=77.52%\n  Epoch 30/100: Loss=116.0673, Acc=77.73%\n  Epoch 40/100: Loss=111.9001, Acc=78.65%\n  Epoch 50/100: Loss=108.2394, Acc=79.53%\n  Epoch 60/100: Loss=105.8206, Acc=80.41%\n  Epoch 70/100: Loss=103.5963, Acc=80.71%\n  Epoch 80/100: Loss=100.6730, Acc=81.55%\n  Epoch 90/100: Loss=97.5831, Acc=81.92%\n  Epoch 100/100: Loss=95.1223, Acc=82.27%\n  Final training accuracy: 82.27%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9793 | Acc=0.9796\n    [Threshold 0.5] -> F1=0.9588 | Acc=0.9592\n    [Best Threshold] = 0.4 with F1=0.9793\n  Testing...\n  Validation loss: 0.8613\n  Validation accuracy: 50.00%\n  Validation F1: 0.4857\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=130.9698, Acc=75.55%\n  Epoch 20/100: Loss=120.5571, Acc=78.13%\n  Epoch 30/100: Loss=115.8281, Acc=79.67%\n  Epoch 40/100: Loss=115.5159, Acc=79.32%\n  Epoch 50/100: Loss=111.8166, Acc=80.40%\n  Epoch 60/100: Loss=108.2210, Acc=81.39%\n  Epoch 70/100: Loss=105.8871, Acc=81.49%\n  Epoch 80/100: Loss=102.9932, Acc=82.09%\n  Epoch 90/100: Loss=100.9454, Acc=82.66%\n  Epoch 100/100: Loss=98.6331, Acc=82.70%\n  Final training accuracy: 82.70%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.8914 | Acc=0.8980\n    [Threshold 0.4] -> F1=0.9140 | Acc=0.9184\n    [Threshold 0.5] -> F1=0.9371 | Acc=0.9388\n    [Best Threshold] = 0.5 with F1=0.9371\n  Testing...\n  Validation loss: 1.0735\n  Validation accuracy: 33.33%\n  Validation F1: 0.3333\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=144.3724, Acc=69.16%\n  Epoch 20/100: Loss=135.1412, Acc=72.34%\n  Epoch 30/100: Loss=129.4445, Acc=73.89%\n  Epoch 40/100: Loss=125.2803, Acc=74.83%\n  Epoch 50/100: Loss=121.5178, Acc=76.52%\n  Epoch 60/100: Loss=115.6259, Acc=77.57%\n  Epoch 70/100: Loss=114.6051, Acc=77.83%\n  Epoch 80/100: Loss=110.3870, Acc=78.81%\n  Epoch 90/100: Loss=108.2491, Acc=79.35%\n  Epoch 100/100: Loss=106.3725, Acc=79.96%\n  Final training accuracy: 79.96%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.3] -> F1=0.9578 | Acc=0.9592\n    [Threshold 0.4] -> F1=0.9790 | Acc=0.9796\n    [Threshold 0.5] -> F1=1.0000 | Acc=1.0000\n    [Best Threshold] = 0.5 with F1=1.0000\n  Testing...\n  Validation loss: 0.4404\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.4542, Acc=71.55%\n  Epoch 20/100: Loss=130.5090, Acc=73.96%\n  Epoch 30/100: Loss=125.9953, Acc=75.55%\n  Epoch 40/100: Loss=120.8461, Acc=76.59%\n  Epoch 50/100: Loss=117.8834, Acc=77.82%\n  Epoch 60/100: Loss=113.7576, Acc=78.61%\n  Epoch 70/100: Loss=110.6972, Acc=79.54%\n  Epoch 80/100: Loss=107.9992, Acc=79.90%\n  Epoch 90/100: Loss=104.2999, Acc=81.14%\n  Epoch 100/100: Loss=104.1253, Acc=81.24%\n  Final training accuracy: 81.24%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8683 | Acc=0.8776\n    [Threshold 0.3] -> F1=0.9361 | Acc=0.9388\n    [Threshold 0.4] -> F1=0.9371 | Acc=0.9388\n    [Threshold 0.5] -> F1=0.9793 | Acc=0.9796\n    [Best Threshold] = 0.5 with F1=0.9793\n  Testing...\n  Validation loss: 0.5284\n  Validation accuracy: 66.67%\n  Validation F1: 0.6667\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=142.3686, Acc=70.85%\n  Epoch 20/100: Loss=132.3822, Acc=73.24%\n  Epoch 30/100: Loss=128.1189, Acc=74.81%\n  Epoch 40/100: Loss=122.6552, Acc=76.18%\n  Epoch 50/100: Loss=119.2723, Acc=77.43%\n  Epoch 60/100: Loss=115.6216, Acc=78.01%\n  Epoch 70/100: Loss=113.5325, Acc=78.32%\n  Epoch 80/100: Loss=110.2615, Acc=79.25%\n  Epoch 90/100: Loss=108.7101, Acc=80.00%\n  Epoch 100/100: Loss=105.5605, Acc=80.56%\n  Final training accuracy: 80.56%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.4378\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 7/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=141.6117, Acc=71.17%\n  Epoch 20/100: Loss=132.7289, Acc=73.91%\n  Epoch 30/100: Loss=126.7131, Acc=75.51%\n  Epoch 40/100: Loss=122.4354, Acc=76.76%\n  Epoch 50/100: Loss=117.9744, Acc=77.48%\n  Epoch 60/100: Loss=115.8887, Acc=78.29%\n  Epoch 70/100: Loss=112.0178, Acc=79.28%\n  Epoch 80/100: Loss=109.2715, Acc=79.70%\n  Epoch 90/100: Loss=106.8605, Acc=80.57%\n  Epoch 100/100: Loss=102.7939, Acc=81.33%\n  Final training accuracy: 81.33%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8498 | Acc=0.8600\n    [Threshold 0.3] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.4] -> F1=0.9380 | Acc=0.9400\n    [Threshold 0.5] -> F1=0.9589 | Acc=0.9600\n    [Best Threshold] = 0.5 with F1=0.9589\n  Testing...\n  Validation loss: 0.3560\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 8/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=139.3299, Acc=73.07%\n  Epoch 20/100: Loss=129.6539, Acc=75.17%\n  Epoch 30/100: Loss=124.9620, Acc=76.70%\n  Epoch 40/100: Loss=121.2630, Acc=77.36%\n  Epoch 50/100: Loss=117.0414, Acc=78.73%\n  Epoch 60/100: Loss=111.7573, Acc=79.58%\n  Epoch 70/100: Loss=108.7685, Acc=80.21%\n  Epoch 80/100: Loss=107.2322, Acc=80.11%\n  Epoch 90/100: Loss=104.9535, Acc=81.19%\n  Epoch 100/100: Loss=102.6455, Acc=81.47%\n  Final training accuracy: 81.47%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9167 | Acc=0.9200\n    [Threshold 0.4] -> F1=0.9796 | Acc=0.9800\n    [Threshold 0.5] -> F1=0.9798 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9798\n  Testing...\n  Validation loss: 0.6011\n  Validation accuracy: 80.00%\n  Validation F1: 0.8000\n\n--- Fold 9/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=133.8541, Acc=72.55%\n  Epoch 20/100: Loss=126.2198, Acc=75.54%\n  Epoch 30/100: Loss=119.5264, Acc=77.43%\n  Epoch 40/100: Loss=115.0780, Acc=78.75%\n  Epoch 50/100: Loss=113.3200, Acc=78.72%\n  Epoch 60/100: Loss=110.4094, Acc=79.62%\n  Epoch 70/100: Loss=108.2578, Acc=79.73%\n  Epoch 80/100: Loss=105.1726, Acc=80.72%\n  Epoch 90/100: Loss=105.2585, Acc=80.57%\n  Epoch 100/100: Loss=101.5987, Acc=81.43%\n  Final training accuracy: 81.43%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8264 | Acc=0.8400\n    [Threshold 0.3] -> F1=0.8727 | Acc=0.8800\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 1.3450\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 10/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=138.2750, Acc=72.17%\n  Epoch 20/100: Loss=128.3926, Acc=74.92%\n  Epoch 30/100: Loss=121.9934, Acc=76.75%\n  Epoch 40/100: Loss=117.6182, Acc=77.78%\n  Epoch 50/100: Loss=114.7586, Acc=78.71%\n  Epoch 60/100: Loss=111.8975, Acc=78.92%\n  Epoch 70/100: Loss=109.8022, Acc=79.85%\n  Epoch 80/100: Loss=108.1117, Acc=80.24%\n  Epoch 90/100: Loss=105.2251, Acc=81.08%\n  Epoch 100/100: Loss=101.4403, Acc=81.64%\n  Final training accuracy: 81.64%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.8949 | Acc=0.9000\n    [Threshold 0.3] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.4] -> F1=0.9589 | Acc=0.9600\n    [Threshold 0.5] -> F1=0.9796 | Acc=0.9800\n    [Best Threshold] = 0.5 with F1=0.9796\n  Testing...\n  Validation loss: 1.1269\n  Validation accuracy: 40.00%\n  Validation F1: 0.4000\n\n  Repetition 10 Results:\n  Mean accuracy: 73.00% ± 25.23%\n  Mean F1: 0.7269 ± 0.2545\n\n✓ Saved results to ./results/final_results_cn_ad_dtca.npz\n\n================================================================================\nFINAL RESULTS\n================================================================================\nAccuracy    : 0.7740 ± 0.1901\nPrecision   : 0.8645 ± 0.1927\nRecall      : 0.7383 ± 0.2503\nF1-score    : 0.7638 ± 0.1976\n\nGlobal AUC: 0.7681\n✓ Saved ROC curve to ./results/roc_curve.png\n\n[3/3] Running CN vs FTD experiment...\n\n================================================================================\nRUNNING EXPERIMENT: CN_FTD\n================================================================================\nSeed set to: 0\n\n--- Loading data ---\nData shapes - PTE: (5907, 5, 6, 6), DE: (5907, 6, 5), Labels: (5907,)\nUsing device: cuda\n\n================================================================================\nREPETITION 1/10\n================================================================================\n\n--- Fold 1/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=120.7252, Acc=64.01%\n  Epoch 20/100: Loss=117.2683, Acc=65.37%\n  Epoch 30/100: Loss=112.6997, Acc=67.61%\n  Epoch 40/100: Loss=108.0623, Acc=70.50%\n  Epoch 50/100: Loss=104.5697, Acc=70.75%\n  Epoch 60/100: Loss=102.9564, Acc=71.81%\n  Epoch 70/100: Loss=100.2205, Acc=73.25%\n  Epoch 80/100: Loss=97.6072, Acc=74.43%\n  Epoch 90/100: Loss=95.3396, Acc=75.07%\n  Epoch 100/100: Loss=95.4261, Acc=75.13%\n  Final training accuracy: 75.13%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.6947 | Acc=0.7027\n    [Threshold 0.3] -> F1=0.7539 | Acc=0.7568\n    [Threshold 0.4] -> F1=0.7824 | Acc=0.7838\n    [Threshold 0.5] -> F1=0.8377 | Acc=0.8378\n    [Best Threshold] = 0.5 with F1=0.8377\n  Testing...\n  Validation loss: 0.4566\n  Validation accuracy: 100.00%\n  Validation F1: 1.0000\n\n--- Fold 2/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=118.1916, Acc=65.72%\n  Epoch 20/100: Loss=114.3053, Acc=68.07%\n  Epoch 30/100: Loss=110.1041, Acc=70.87%\n  Epoch 40/100: Loss=107.0260, Acc=71.54%\n  Epoch 50/100: Loss=102.3949, Acc=73.12%\n  Epoch 60/100: Loss=100.6804, Acc=74.34%\n  Epoch 70/100: Loss=96.4425, Acc=75.35%\n  Epoch 80/100: Loss=93.2325, Acc=76.60%\n  Epoch 90/100: Loss=91.2969, Acc=76.93%\n  Epoch 100/100: Loss=89.3013, Acc=77.70%\n  Final training accuracy: 77.70%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.7539 | Acc=0.7568\n    [Threshold 0.3] -> F1=0.7824 | Acc=0.7838\n    [Threshold 0.4] -> F1=0.8377 | Acc=0.8378\n    [Threshold 0.5] -> F1=0.8645 | Acc=0.8649\n    [Best Threshold] = 0.5 with F1=0.8645\n  Testing...\n  Validation loss: 0.6954\n  Validation accuracy: 60.00%\n  Validation F1: 0.5833\n\n--- Fold 3/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=116.2992, Acc=69.17%\n  Epoch 20/100: Loss=112.5877, Acc=70.46%\n  Epoch 30/100: Loss=108.9945, Acc=71.71%\n  Epoch 40/100: Loss=105.8233, Acc=73.24%\n  Epoch 50/100: Loss=103.5525, Acc=73.08%\n  Epoch 60/100: Loss=100.6229, Acc=75.02%\n  Epoch 70/100: Loss=98.1259, Acc=75.33%\n  Epoch 80/100: Loss=95.3937, Acc=76.76%\n  Epoch 90/100: Loss=93.7303, Acc=76.59%\n  Epoch 100/100: Loss=91.9712, Acc=77.40%\n  Final training accuracy: 77.40%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.7590 | Acc=0.7632\n    [Threshold 0.3] -> F1=0.7871 | Acc=0.7895\n    [Threshold 0.4] -> F1=0.8417 | Acc=0.8421\n    [Threshold 0.5] -> F1=0.8417 | Acc=0.8421\n    [Best Threshold] = 0.4 with F1=0.8417\n  Testing...\n  Validation loss: 0.9982\n  Validation accuracy: 25.00%\n  Validation F1: 0.2000\n\n--- Fold 4/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=114.4834, Acc=68.35%\n  Epoch 20/100: Loss=110.6852, Acc=69.84%\n  Epoch 30/100: Loss=108.9204, Acc=69.84%\n  Epoch 40/100: Loss=106.1226, Acc=71.25%\n  Epoch 50/100: Loss=104.1786, Acc=72.55%\n  Epoch 60/100: Loss=101.3004, Acc=73.99%\n  Epoch 70/100: Loss=97.9881, Acc=74.25%\n  Epoch 80/100: Loss=96.8674, Acc=75.25%\n  Epoch 90/100: Loss=95.9658, Acc=74.68%\n  Epoch 100/100: Loss=93.0402, Acc=75.88%\n  Final training accuracy: 75.88%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.7004 | Acc=0.7105\n    [Threshold 0.3] -> F1=0.7590 | Acc=0.7632\n    [Threshold 0.4] -> F1=0.7871 | Acc=0.7895\n    [Threshold 0.5] -> F1=0.7871 | Acc=0.7895\n    [Best Threshold] = 0.4 with F1=0.7871\n  Testing...\n  Validation loss: 0.6612\n  Validation accuracy: 50.00%\n  Validation F1: 0.5000\n\n--- Fold 5/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=114.8077, Acc=69.38%\n  Epoch 20/100: Loss=112.5768, Acc=70.60%\n  Epoch 30/100: Loss=110.1057, Acc=71.42%\n  Epoch 40/100: Loss=103.6171, Acc=74.24%\n  Epoch 50/100: Loss=99.8712, Acc=76.28%\n  Epoch 60/100: Loss=96.9111, Acc=76.07%\n  Epoch 70/100: Loss=93.9660, Acc=77.18%\n  Epoch 80/100: Loss=92.0771, Acc=78.14%\n  Epoch 90/100: Loss=90.0512, Acc=78.91%\n  Epoch 100/100: Loss=86.7583, Acc=79.53%\n  Final training accuracy: 79.53%\n  Tuning threshold...\n    [Threshold 0.2] -> F1=0.7617 | Acc=0.7632\n    [Threshold 0.3] -> F1=0.7889 | Acc=0.7895\n    [Threshold 0.4] -> F1=0.8421 | Acc=0.8421\n    [Threshold 0.5] -> F1=0.8683 | Acc=0.8684\n    [Best Threshold] = 0.5 with F1=0.8683\n  Testing...\n  Validation loss: 0.9299\n  Validation accuracy: 50.00%\n  Validation F1: 0.5000\n\n--- Fold 6/10 ---\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Epoch 10/100: Loss=120.3418, Acc=68.42%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1457060736.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;31m# Step 3: Run CN vs FTD experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[3/3] Running CN vs FTD experiment...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m     \u001b[0mresults_cn_ftd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cn_ftd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1457060736.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             label_acc_history = train_model(\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0msource_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/1457060736.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, source_dataloader, target_dataloader, criterion_label, optimizer, num_epochs, device, scheduler)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0mloss_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# Add this code at the end of your notebook\nimport shutil\nimport os\n\n# Create a zip file of all results\noutput_dir = '/kaggle/working'\nzip_filename = '/kaggle/working/all_results'\n\nshutil.make_archive(zip_filename, 'zip', output_dir)\nprint(f\"Created: {zip_filename}.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:56:54.078485Z","iopub.execute_input":"2025-10-13T17:56:54.078983Z","iopub.status.idle":"2025-10-13T17:57:02.890206Z","shell.execute_reply.started":"2025-10-13T17:56:54.078959Z","shell.execute_reply":"2025-10-13T17:57:02.889576Z"}},"outputs":[{"name":"stdout","text":"Created: /kaggle/working/all_results.zip\n","output_type":"stream"}],"execution_count":4}]}