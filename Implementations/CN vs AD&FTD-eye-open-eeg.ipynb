{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10720773,"sourceType":"datasetVersion","datasetId":6645569},{"sourceId":13677374,"sourceType":"datasetVersion","datasetId":8697304}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:24:32.411246Z","iopub.execute_input":"2025-11-10T12:24:32.411424Z","iopub.status.idle":"2025-11-10T12:24:37.808345Z","shell.execute_reply.started":"2025-11-10T12:24:32.411408Z","shell.execute_reply":"2025-11-10T12:24:37.807457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nimportant\nDTCA-Net: Dual-Transformer Cross Attention Network\nComplete pipeline for AD/FTD detection from EEG signals\nFIXED VERSION - Ready for full dataset with NaN handling\n\"\"\"\n\nimport os\nimport re\nimport glob\nimport random\nimport math\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nfrom typing import Tuple, List\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport mne\nimport pywt\nfrom scipy.signal import hilbert\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, precision_score, \n    recall_score, roc_auc_score, roc_curve\n)\nfrom sklearn.utils import check_random_state\nfrom imblearn.over_sampling import SMOTE\n\nimport numba as nb\n\n# ═══════════════════════════════════════════════════════════════════════════\n# CONFIGURATION\n# ═══════════════════════════════════════════════════════════════════════════\n\n# Paths\nDATA_DIR = \"/kaggle/input/eye-open-eeg-alzheimers/eye-open-dataset\"\nFEATURES_DIR = \"./features\"\nRESULTS_DIR = \"./results\"\n\n# Create directories\nos.makedirs(FEATURES_DIR, exist_ok=True)\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# DWT Configuration\nMAX_LVL = 8\nWAVELET = 'db4'\nband2levels = {\n    'delta': [1, 2, 3],\n    'theta': [4],\n    'alpha': [5],\n    'beta': [6],\n    'gamma': [7]\n}\nband_list = list(band2levels.keys())\n\n# Window Configuration - FIXED TO MATCH\nMINUTE_LEN = 60\nSFREQ = 256\nMINUTE_SAMPLES = int(MINUTE_LEN * SFREQ)  # 15360 samples per minute\nN_SUBWINS_PER_MINUTE = 11  # Fixed number of sub-windows per minute\n\n# Model Configuration\nSELECTED_CHANNELS = ['O1', 'O2', 'T4', 'T5', 'F7', 'F8']\nBATCH_SIZE = 32\nN_SPLITS = 10\nN_REPETITIONS = 10\nNUM_EPOCHS = 100\nLEARNING_RATE = 0.0001\n\n# ═══════════════════════════════════════════════════════════════════════════\n# UTILITY FUNCTIONS\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef set_seed(seed: int):\n    \"\"\"Set random seed for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    _ = check_random_state(seed)\n    print(f\"Seed set to: {seed}\")\n\ndef get_subject_id(filepath: str) -> int:\n    \"\"\"Extract subject ID from filepath.\"\"\"\n    for part in filepath.split(os.sep):\n        if part.startswith('sub-'):\n            return int(part.replace('sub-', '').strip())\n    return None\n\n# ═══════════════════════════════════════════════════════════════════════════\n# FEATURE EXTRACTION: PTE\n# ═══════════════════════════════════════════════════════════════════════════\n\n@nb.njit(fastmath=True, cache=True)\ndef _entropy(counts, length):\n    \"\"\"Calculate entropy.\"\"\"\n    H = 0.0\n    for c in counts:\n        if c > 0:\n            p = c / length\n            H -= p * np.log2(p)\n    return H\n\n@nb.njit(fastmath=True, cache=True)\ndef compute_PTE_numba(phase, delay):\n    \"\"\"Compute Phase Transfer Entropy using Numba JIT.\"\"\"\n    m, n = phase.shape\n    raw = np.zeros((m, m), np.float64)\n    L = n - delay\n    \n    for i in range(m):\n        x = phase[i, :L]\n        for j in range(m):\n            y = phase[j, :L]\n            ypr = phase[j, delay:]\n            vmax = int(max(x.max(), y.max(), ypr.max()) + 1)\n            \n            cnt_y = np.bincount(y, minlength=vmax)\n            idx_ypr_y = ypr + vmax * y\n            cnt_ypr_y = np.bincount(idx_ypr_y, minlength=vmax * vmax)\n            idx_y_x = y + vmax * x\n            cnt_y_x = np.bincount(idx_y_x, minlength=vmax * vmax)\n            idx_3d = ypr + vmax * (y + vmax * x)\n            cnt_3d = np.bincount(idx_3d, minlength=vmax * vmax * vmax)\n            \n            Hy = _entropy(cnt_y, L)\n            Hypr = _entropy(cnt_ypr_y, L)\n            Hyx = _entropy(cnt_y_x, L)\n            Hyprx = _entropy(cnt_3d, L)\n            \n            raw[i, j] = Hypr + Hyx - Hy - Hyprx\n    \n    return raw\n\n@nb.njit(fastmath=True, cache=True)\ndef dPTE_from_raw(raw):\n    \"\"\"Compute directed PTE from raw PTE.\"\"\"\n    sym = raw + raw.T\n    # Add small epsilon to avoid division by zero\n    eps = 1e-10\n    result = np.zeros_like(raw)\n    for i in range(raw.shape[0]):\n        for j in range(raw.shape[1]):\n            if sym[i, j] > eps:\n                result[i, j] = raw[i, j] / sym[i, j]\n            else:\n                result[i, j] = 0.0\n    return np.triu(result, 1) + np.tril(result.T, -1)\n\ndef reconstruct_band_dwt(data: np.ndarray, levels: List[int]) -> np.ndarray:\n    \"\"\"Reconstruct signal from specific DWT levels with NaN handling.\"\"\"\n    try:\n        coeffs = pywt.wavedec(data, WAVELET, axis=1, level=MAX_LVL)\n        kept = [np.zeros_like(c) for c in coeffs]\n        for lv in levels:\n            kept[lv] = coeffs[lv]\n        reconstructed = pywt.waverec(kept, WAVELET, axis=1)\n        \n        # Handle any NaN or Inf values\n        reconstructed = np.nan_to_num(reconstructed, nan=0.0, posinf=0.0, neginf=0.0)\n        \n        return reconstructed\n    except Exception as e:\n        print(f\"Warning: DWT reconstruction failed: {e}. Returning zeros.\")\n        return np.zeros_like(data)\n\ndef get_delay(phase: np.ndarray) -> int:\n    \"\"\"Estimate optimal delay for PTE.\"\"\"\n    m, n = phase.shape\n    c1 = m * n\n    c2 = (phase * np.roll(phase, 1, axis=1) < 0).sum()\n    if c2 == 0:\n        return 1\n    return max(1, int(round(c1 / c2)))\n\ndef get_binsize(phase: np.ndarray, c: float = 3.49) -> float:\n    \"\"\"Calculate bin size for phase discretization.\"\"\"\n    m, n = phase.shape\n    std_vals = np.std(phase, axis=1, ddof=1)\n    mean_std = np.mean(std_vals)\n    if mean_std == 0 or np.isnan(mean_std):\n        return 0.1  # Default small bin size\n    binsz = c * mean_std * n ** (-1 / 3)\n    return max(binsz, 0.01)  # Ensure minimum bin size\n\ndef discretize_phase(phase: np.ndarray, binsz: float) -> np.ndarray:\n    \"\"\"Discretize phase values.\"\"\"\n    return np.ceil(phase / binsz).astype(np.int32)\n\ndef process_pte_subject(filepath: str, label: str):\n    \"\"\"Process one subject for PTE feature extraction.\"\"\"\n    print(f\"Processing PTE: {filepath}\")\n    raw = mne.io.read_raw_eeglab(filepath, preload=True, verbose='ERROR')\n    raw.resample(SFREQ)\n    \n    data_full = raw.get_data()\n    n_ch = data_full.shape[0]\n    total_samples = data_full.shape[1]\n    \n    n_minutes = total_samples // MINUTE_SAMPLES\n    n_bands = len(band_list)\n    subwin_samples = MINUTE_SAMPLES // N_SUBWINS_PER_MINUTE\n    \n    # Shape: (n_minutes, n_subwins, n_bands, n_ch, n_ch)\n    dp_subject = np.zeros((n_minutes, N_SUBWINS_PER_MINUTE, n_bands, n_ch, n_ch), dtype=np.float64)\n    \n    for mi in range(n_minutes):\n        seg60 = data_full[:, mi * MINUTE_SAMPLES:(mi + 1) * MINUTE_SAMPLES]\n        \n        for bi, band in enumerate(band_list):\n            levels = band2levels[band]\n            band_data = reconstruct_band_dwt(seg60, levels)\n            phase = np.angle(hilbert(band_data, axis=1))\n            \n            # Handle NaN in phase\n            phase = np.nan_to_num(phase, nan=0.0, posinf=0.0, neginf=0.0)\n            \n            delay = get_delay(phase)\n            binsz = get_binsize(phase)\n            dph = discretize_phase(phase + np.pi, binsz)\n            \n            for wi in range(N_SUBWINS_PER_MINUTE):\n                start = wi * subwin_samples\n                end = start + subwin_samples\n                blk = dph[:, start:end]\n                rawP = compute_PTE_numba(blk, delay)\n                dp = dPTE_from_raw(rawP)\n                \n                # Ensure no NaN or Inf\n                dp = np.nan_to_num(dp, nan=0.0, posinf=0.0, neginf=0.0)\n                \n                dp_subject[mi, wi, bi, :, :] = dp\n    \n    subj_id = get_subject_id(filepath)\n    return subj_id, dp_subject, label\n\n# ═══════════════════════════════════════════════════════════════════════════\n# FEATURE EXTRACTION: DIFFERENTIAL ENTROPY\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef compute_DE(signal: np.ndarray) -> float:\n    \"\"\"Compute differential entropy with robust NaN handling.\"\"\"\n    # Remove any NaN or Inf values\n    signal = signal[np.isfinite(signal)]\n    \n    if len(signal) < 2:\n        return 0.0\n    \n    var = np.var(signal, ddof=1)\n    \n    # Handle zero or negative variance\n    if var <= 1e-10 or not np.isfinite(var):\n        return 0.0\n    \n    de = 0.5 * math.log(2 * math.pi * math.e * var)\n    \n    # Ensure result is finite\n    if not np.isfinite(de):\n        return 0.0\n    \n    return de\n\ndef process_de_subject(filepath: str, label: str):\n    \"\"\"Process one subject for DE feature extraction - FIXED TO MATCH PTE.\"\"\"\n    print(f\"Processing DE: {filepath}\")\n    \n    raw = mne.io.read_raw_eeglab(filepath, preload=True, verbose='ERROR')\n    raw.resample(SFREQ)\n    \n    data = raw.get_data() * 1e6\n    \n    # Clean data - remove NaN/Inf\n    data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    n_ch = data.shape[0]\n    n_samp = data.shape[1]\n    \n    n_minutes = n_samp // MINUTE_SAMPLES\n    subwin_samples = MINUTE_SAMPLES // N_SUBWINS_PER_MINUTE\n    \n    # Shape: (n_minutes * n_subwins, n_ch, n_bands)\n    total_windows = n_minutes * N_SUBWINS_PER_MINUTE\n    DE_values = np.zeros((total_windows, n_ch, len(band_list)), dtype=float)\n    \n    win_idx = 0\n    for mi in range(n_minutes):\n        seg60 = data[:, mi * MINUTE_SAMPLES:(mi + 1) * MINUTE_SAMPLES]\n        \n        # Extract band signals for the entire minute\n        band_sigs = {}\n        for band in band_list:\n            band_sig = reconstruct_band_dwt(seg60, band2levels[band])\n            # Ensure no NaN\n            band_sig = np.nan_to_num(band_sig, nan=0.0, posinf=0.0, neginf=0.0)\n            band_sigs[band] = band_sig\n        \n        # Divide into sub-windows\n        for wi in range(N_SUBWINS_PER_MINUTE):\n            start = wi * subwin_samples\n            end = start + subwin_samples\n            \n            for bi, band in enumerate(band_list):\n                sig_window = band_sigs[band][:, start:end]\n                for ch in range(n_ch):\n                    de_val = compute_DE(sig_window[ch])\n                    DE_values[win_idx, ch, bi] = de_val\n            \n            win_idx += 1\n    \n    # Final check for NaN values\n    DE_values = np.nan_to_num(DE_values, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    subj_id = get_subject_id(filepath)\n    return subj_id, DE_values, label\n\n# ═══════════════════════════════════════════════════════════════════════════\n# DATA LOADING\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef load_data_stratified_kfold(\n    pte_directory: str,\n    DE_directory: str,\n    batch_size: int,\n    selected_classes=(\"alz\", \"ctrl\"),\n    selected_channels=None,\n    n_splits: int = 10,\n    n_repetitions: int = 5,\n):\n    \"\"\"Load and prepare data with stratified k-fold cross-validation.\"\"\"\n    ch_names = [\n        \"Fp1\", \"Fp2\", \"F3\", \"F4\", \"C3\", \"C4\", \"P3\", \"P4\", \"O1\", \"O2\",\n        \"F7\", \"F8\", \"T3\", \"T4\", \"T5\", \"T6\", \"Fz\", \"Cz\", \"Pz\",\n    ]\n    \n    if selected_channels is None:\n        selected_channels = ch_names\n    \n    sel_idx = [ch_names.index(ch) for ch in selected_channels]\n    label_map = {c: i for i, c in enumerate(selected_classes)}\n    \n    def parse_info(fname):\n        m = re.match(r\"sub-(\\d+)_.*_(\\w+)\\.npz\", fname)\n        if not m:\n            return None\n        sid, lbl = int(m.group(1)), m.group(2).lower()\n        if lbl not in selected_classes:\n            return None\n        return sid, lbl\n    \n    def collect_files(directory, file_type='PTE'):\n        \"\"\"Collect files of specific type (PTE or DE).\"\"\"\n        all_files = sorted(\n            [f for f in os.listdir(directory) if f.endswith(\".npz\") and f\"_{file_type}_\" in f],\n            key=lambda f: int(re.search(r\"sub-(\\d+)_\", f).group(1)),\n        )\n        info = [parse_info(f) + (f,) for f in all_files if parse_info(f) is not None]\n        \n        # Drop first 5 subjects from each class\n        drop_ids = {}\n        for cls in selected_classes:\n            ids = sorted({sid for sid, lbl, _ in info if lbl == cls})\n            drop_ids[cls] = set(ids[:5])\n        \n        return [\n            fname\n            for sid, lbl, fname in info\n            if sid not in drop_ids[lbl]\n        ]\n    \n    pte_files = collect_files(pte_directory, file_type='PTE')\n    psd_files = collect_files(DE_directory, file_type='DE')\n    \n    pte_list, psd_list, labels_list, pid_list = [], [], [], []\n    \n    for fname in pte_files:\n        sid, lbl = parse_info(fname)\n        lbl_int = label_map[lbl]\n        arr = np.load(Path(pte_directory) / fname, allow_pickle=True)\n        \n        pte = arr[\"pte_data\"]\n        # Clean PTE data\n        pte = np.nan_to_num(pte, nan=0.0, posinf=0.0, neginf=0.0)\n        \n        # Reshape from (n_minutes, 11, 5, 19, 19) to (n_minutes*11, 5, 19, 19)\n        n_minutes = pte.shape[0]\n        pte = pte.reshape(n_minutes * N_SUBWINS_PER_MINUTE, *pte.shape[2:])\n        # Select channels\n        pte = pte[:, :, sel_idx, :][:, :, :, sel_idx]\n        \n        N = pte.shape[0]\n        pte_list.append(pte)\n        labels_list.append(np.full(N, lbl_int, dtype=int))\n        pid_list.extend([sid] * N)\n    \n    for fname in psd_files:\n        sid, _ = parse_info(fname)\n        arr = np.load(Path(DE_directory) / fname, allow_pickle=True)\n        \n        psd = arr[\"DE_features\"]\n        # Clean DE data\n        psd = np.nan_to_num(psd, nan=0.0, posinf=0.0, neginf=0.0)\n        \n        psd = psd[:, sel_idx, :]\n        \n        psd_list.append(psd)\n    \n    X_pte = np.concatenate(pte_list, axis=0)\n    X_psd = np.concatenate(psd_list, axis=0)\n    y = np.concatenate(labels_list, axis=0)\n    pid = np.asarray(pid_list, dtype=int)\n    \n    # Final safety check\n    X_pte = np.nan_to_num(X_pte, nan=0.0, posinf=0.0, neginf=0.0)\n    X_psd = np.nan_to_num(X_psd, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    print(f\"Data shapes - PTE: {X_pte.shape}, DE: {X_psd.shape}, Labels: {y.shape}\")\n    print(f\"NaN check - PTE: {np.isnan(X_pte).sum()}, DE: {np.isnan(X_psd).sum()}\")\n    \n    assert X_pte.shape[0] == X_psd.shape[0] == y.shape[0] == pid.shape[0], \\\n        f\"Shape mismatch! PTE: {X_pte.shape[0]}, DE: {X_psd.shape[0]}, Labels: {y.shape[0]}, PID: {pid.shape[0]}\"\n    \n    unique_pids = np.unique(pid)\n    subj_labels = np.array(\n        [Counter(y[pid == sid]).most_common(1)[0][0] for sid in unique_pids]\n    )\n    \n    all_reps = []\n    for rep in range(n_repetitions):\n        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rep)\n        rep_folds = []\n        \n        for subj_tr_idx, subj_va_idx in skf.split(unique_pids, subj_labels):\n            train_pids = unique_pids[subj_tr_idx]\n            val_pids = unique_pids[subj_va_idx]\n            \n            tr_mask = np.isin(pid, train_pids)\n            va_mask = np.isin(pid, val_pids)\n            \n            Xp_tr, Xp_va = X_pte[tr_mask], X_pte[va_mask]\n            Xs_tr, Xs_va = X_psd[tr_mask], X_psd[va_mask]\n            y_tr, y_va = y[tr_mask], y[va_mask]\n            pid_tr, pid_va = pid[tr_mask], pid[va_mask]\n            \n            flat_pte_tr = Xp_tr.reshape(len(y_tr), -1)\n            flat_psd_tr = Xs_tr.reshape(len(y_tr), -1)\n            X_train_flat = np.hstack([flat_pte_tr, flat_psd_tr])\n            \n            # Additional NaN check before SMOTE\n            X_train_flat = np.nan_to_num(X_train_flat, nan=0.0, posinf=0.0, neginf=0.0)\n            \n            sm = SMOTE(random_state=rep)\n            X_bal, y_bal = sm.fit_resample(X_train_flat, y_tr)\n            \n            if hasattr(sm, \"sample_indices_\"):\n                res_idx = sm.sample_indices_\n            elif hasattr(sm, \"_sample_indices\"):\n                res_idx = sm._sample_indices\n            else:\n                idx = np.arange(len(y_tr)).reshape(-1, 1)\n                idx_bal, _ = SMOTE(random_state=rep).fit_resample(idx, y_tr)\n                res_idx = idx_bal.ravel()\n            \n            pid_bal = pid_tr[res_idx]\n            \n            split_at = flat_pte_tr.shape[1]\n            flat_pte_bal = X_bal[:, :split_at]\n            flat_psd_bal = X_bal[:, split_at:]\n            \n            scaler_pte = MinMaxScaler()\n            scaler_psd = MinMaxScaler()\n            \n            flat_pte_bal = scaler_pte.fit_transform(flat_pte_bal)\n            flat_pte_val = scaler_pte.transform(Xp_va.reshape(len(y_va), -1))\n            \n            flat_psd_bal = scaler_psd.fit_transform(flat_psd_bal)\n            flat_psd_val = scaler_psd.transform(Xs_va.reshape(len(y_va), -1))\n            \n            Xp_tr_bal = flat_pte_bal.reshape(-1, *Xp_tr.shape[1:])\n            Xs_tr_bal = flat_psd_bal.reshape(-1, *Xs_tr.shape[1:])\n            Xp_va = flat_pte_val.reshape(Xp_va.shape)\n            Xs_va = flat_psd_val.reshape(Xs_va.shape)\n            \n            def make_loader(x1, x2, y_, p_, shuffle):\n                t1 = torch.from_numpy(x1).float()\n                t2 = torch.from_numpy(x2).float()\n                ty = torch.from_numpy(y_).long()\n                tp = torch.from_numpy(p_).long()\n                ds = TensorDataset(t1, t2, ty, tp)\n                return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n            \n            train_loader = make_loader(Xp_tr_bal, Xs_tr_bal, y_bal, pid_bal, shuffle=True)\n            val_loader = make_loader(Xp_va, Xs_va, y_va, pid_va, shuffle=False)\n            \n            rep_folds.append((train_loader, val_loader))\n        \n        all_reps.append(rep_folds)\n    \n    return all_reps\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MODEL ARCHITECTURE\n# ═══════════════════════════════════════════════════════════════════════════\n\nclass MultiHeadCrossAttention(nn.Module):\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super(MultiHeadCrossAttention, self).__init__()\n        self.multihead_attn = nn.MultiheadAttention(\n            embed_dim=d_model, \n            num_heads=num_heads, \n            dropout=dropout, \n            batch_first=True\n        )\n        self.layer_norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n        attn_output, attn_weights = self.multihead_attn(\n            query, key, value, \n            attn_mask=attn_mask, \n            key_padding_mask=key_padding_mask\n        )\n        attn_output = self.dropout(attn_output)\n        output = self.layer_norm(query + attn_output)\n        return output, attn_weights\n\nclass PteTransformer(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n        super(PteTransformer, self).__init__()\n        # PTE input: (batch, 5_bands, 6_channels, 6_channels) = (batch, 5, 6, 6)\n        # Flatten to: (batch, 5, 36) - treat bands as sequence\n        self.flatten_spatial = nn.Flatten(start_dim=2)  # Flatten spatial dimensions\n        spatial_dim = 36  # 6 * 6\n        \n        self.position_encoding = nn.Parameter(torch.randn(1, 5, spatial_dim), requires_grad=True)\n        \n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=spatial_dim,\n            nhead=num_heads,\n            dim_feedforward=hidden_dim,\n            dropout=dropout,\n            batch_first=True,\n            activation=\"gelu\"\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n        self.output_layer = nn.Linear(spatial_dim, output_dim)\n    \n    def forward(self, x):\n        # x: (batch, 5, 6, 6)\n        b = x.shape[0]\n        x = self.flatten_spatial(x)  # (batch, 5, 36)\n        x = self.position_encoding + x\n        x = self.transformer(x)  # (batch, 5, 36)\n        x = self.output_layer(x)  # (batch, 5, 128)\n        return x\n\nclass PsdTransformer(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, dropout):\n        super(PsdTransformer, self).__init__()\n        # PSD/DE input: (batch, 6_channels, 5_bands)\n        # Transpose to: (batch, 6, 5) - treat channels as sequence\n        \n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=input_dim,  # 5 bands\n            nhead=num_heads,\n            dim_feedforward=hidden_dim,\n            dropout=dropout,\n            batch_first=True,\n            activation=\"gelu\"\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n        self.output_layer = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        # x: (batch, 6_channels, 5_bands)\n        x = self.transformer(x)  # (batch, 6, 5)\n        x = self.output_layer(x)  # (batch, 6, 128)\n        return x\n\nclass FinalModel(nn.Module):\n    def __init__(self, \n                 pte_input_dim, pte_hidden_dim, pte_num_layers, pte_num_heads, pte_output_dim, pte_dropout,\n                 psd_input_dim, psd_hidden_dim, psd_num_layers, psd_num_heads, psd_output_dim, psd_dropout,\n                 cross_d_model, cross_num_heads):\n        super(FinalModel, self).__init__()\n        \n        self.pte_transformer = PteTransformer(\n            input_dim=pte_input_dim,\n            hidden_dim=pte_hidden_dim,\n            num_layers=pte_num_layers,\n            num_heads=pte_num_heads,\n            output_dim=pte_output_dim,\n            dropout=pte_dropout\n        )\n        \n        self.psd_transformer = PsdTransformer(\n            input_dim=psd_input_dim,\n            hidden_dim=psd_hidden_dim,\n            num_layers=psd_num_layers,\n            num_heads=psd_num_heads,\n            output_dim=psd_output_dim,\n            dropout=psd_dropout\n        )\n        \n        self.cross_attention = MultiHeadCrossAttention(\n            d_model=cross_d_model,\n            num_heads=cross_num_heads,\n            dropout=0.1\n        )\n        \n        # After cross attention: (batch, 5, 128)\n        # Flatten for classification: (batch, 5*128) = (batch, 640)\n        self.final_classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.5),\n            nn.Linear(5 * 128, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2)\n        )\n    \n    def forward(self, pte_input, psd_input):\n        # pte_input: (batch, 5, 6, 6)\n        # psd_input: (batch, 6, 5)\n        \n        pte_encoded = self.pte_transformer(pte_input)  # (batch, 5, 128)\n        psd_encoded = self.psd_transformer(psd_input)  # (batch, 6, 128)\n        \n        # Cross attention: query from PTE (5 band features), key/value from PSD (6 channel features)\n        cross_attn_output, attn_weights = self.cross_attention(\n            query=pte_encoded,  # (batch, 5, 128)\n            key=psd_encoded,    # (batch, 6, 128)\n            value=psd_encoded   # (batch, 6, 128)\n        )\n        # Output: (batch, 5, 128) - maintains query sequence length\n        \n        label_pred = self.final_classifier(cross_attn_output)  # (batch, 2)\n        \n        return label_pred, attn_weights\n\n# ═══════════════════════════════════════════════════════════════════════════\n# TRAINING AND EVALUATION\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef train_model(\n    model,\n    source_dataloader,\n    target_dataloader,\n    criterion_label,\n    optimizer,\n    num_epochs=10,\n    device=\"cuda\",\n    scheduler=None,\n):\n    model.to(device)\n    model.train()\n    \n    accuracy_history = []\n    \n    for epoch in range(num_epochs):\n        total_correct = 0\n        total_samples = 0\n        epoch_loss = 0.0\n        \n        for batch_src in source_dataloader:\n            if len(batch_src) == 4:\n                source_pte, source_psd, source_labels, _ = batch_src\n            else:\n                source_pte, source_psd, source_labels = batch_src[:3]\n            \n            source_pte = source_pte.to(device)\n            source_psd = source_psd.to(device)\n            source_labels = source_labels.to(device)\n            \n            label_preds, _ = model(source_pte, source_psd)\n            loss_label = criterion_label(label_preds, source_labels)\n            \n            optimizer.zero_grad()\n            loss_label.backward()\n            optimizer.step()\n            \n            epoch_loss += loss_label.item()\n            \n            _, predicted = torch.max(label_preds, dim=1)\n            correct = (predicted == source_labels).sum().item()\n            total_correct += correct\n            total_samples += source_labels.size(0)\n        \n        if scheduler is not None:\n            scheduler.step()\n        \n        epoch_accuracy = 100.0 * total_correct / total_samples if total_samples > 0 else 0\n        accuracy_history.append(epoch_accuracy)\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"  Epoch {epoch+1}/{num_epochs}: Loss={epoch_loss:.4f}, Acc={epoch_accuracy:.2f}%\")\n    \n    return accuracy_history\n\ndef test_model(\n    model,\n    test_dataloader,\n    criterion_label,\n    device=\"cuda\",\n    num_classes=2,\n    alz_threshold=0.4\n):\n    model.to(device).eval()\n    total_loss = 0.0\n    \n    all_preds = []\n    all_labels = []\n    all_probs = []\n    all_pids = []\n    \n    with torch.no_grad():\n        for batch in test_dataloader:\n            if len(batch) == 4:\n                pte, psd, labels, pids = batch\n            else:\n                pte, psd, labels = batch\n                pids = torch.zeros_like(labels)\n            \n            pte, psd, labels = pte.to(device), psd.to(device), labels.to(device)\n            logits, _ = model(pte, psd)\n            loss = criterion_label(logits, labels)\n            total_loss += loss.item()\n            \n            probs = F.softmax(logits, dim=1)\n            preds = probs.argmax(dim=1)\n            \n            all_probs.append(probs.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            all_pids.extend(pids.cpu().numpy())\n    \n    n_batches = len(test_dataloader)\n    avg_loss = total_loss / n_batches if n_batches else 0.0\n    \n    all_probs = np.vstack(all_probs)\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_pids = np.array(all_pids)\n    \n    part_ids = np.unique(all_pids)\n    part_accs = []\n    part_preds = []\n    part_confs = np.zeros((num_classes, num_classes), dtype=int)\n    part_ratios = []\n    part_trues = []\n    \n    for pid in part_ids:\n        mask = (all_pids == pid)\n        labs = all_labels[mask]\n        preds = all_preds[mask]\n        \n        true_lbl = labs[0]\n        alz_ratio = (preds == 1).sum() / max(len(preds), 1)\n        pred_lbl = 1 if alz_ratio >= alz_threshold else 0\n        \n        part_confs[true_lbl, pred_lbl] += 1\n        part_accs.append(100.0 if pred_lbl == true_lbl else 0.0)\n        \n        part_preds.append(pred_lbl)\n        part_ratios.append(alz_ratio)\n        part_trues.append(true_lbl)\n    \n    mean_acc = float(np.mean(part_accs)) if part_accs else 0.0\n    mean_f1 = f1_score(part_trues, part_preds, average='macro', zero_division=0) if part_trues else 0.0\n    \n    return (\n        avg_loss,\n        mean_acc,\n        mean_f1,\n        part_confs,\n        all_probs,\n        all_labels,\n        np.array(part_ratios),\n        np.array(part_trues)\n    )\n\ndef tune_threshold_on_source(\n    model,\n    source_dataloader,\n    device=\"cuda\",\n    thresholds=[0.1, 0.2, 0.3, 0.4, 0.5],\n    num_classes=2\n):\n    model.eval()\n    model.to(device)\n    sample_preds = defaultdict(list)\n    participant_label = {}\n    \n    with torch.no_grad():\n        for batch in source_dataloader:\n            if len(batch) == 4:\n                pte_batch, psd_batch, labels, pid_batch = batch\n            else:\n                raise ValueError(\"Expected Dataloader to return (pte, psd, labels, pid).\")\n            \n            pte_batch = pte_batch.to(device)\n            psd_batch = psd_batch.to(device)\n            labels = labels.to(device)\n            pid_batch = pid_batch.to(device)\n            \n            label_preds, _ = model(pte_batch, psd_batch)\n            softmax_output = F.softmax(label_preds, dim=1)\n            _, predicted = torch.max(softmax_output, dim=1)\n            \n            predicted = predicted.cpu().numpy()\n            labels = labels.cpu().numpy()\n            pid_batch = pid_batch.cpu().numpy()\n            \n            for pred, true_lbl, pid in zip(predicted, labels, pid_batch):\n                sample_preds[pid].append(pred)\n                if pid not in participant_label:\n                    participant_label[pid] = true_lbl\n    \n    best_threshold = None\n    best_metric_val = -1.0\n    \n    for thr in thresholds:\n        part_level_preds = []\n        part_level_trues = []\n        \n        for pid, preds_list in sample_preds.items():\n            true_lbl = participant_label[pid]\n            n_alz = sum([p == 1 for p in preds_list])\n            ratio = float(n_alz) / len(preds_list)\n            participant_pred = 1 if ratio >= thr else 0\n            \n            part_level_preds.append(participant_pred)\n            part_level_trues.append(true_lbl)\n        \n        f1 = f1_score(part_level_trues, part_level_preds, average='macro', zero_division=0)\n        acc = accuracy_score(part_level_trues, part_level_preds)\n        \n        print(f\"    [Threshold {thr}] -> F1={f1:.4f} | Acc={acc:.4f}\")\n        \n        if f1 > best_metric_val:\n            best_metric_val = f1\n            best_threshold = thr\n    \n    print(f\"    [Best Threshold] = {best_threshold} with F1={best_metric_val:.4f}\")\n    return best_threshold\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MAIN PIPELINE\n# ═══════════════════════════════════════════════════════════════════════════\n\ndef extract_features():\n    \"\"\"Extract PTE and DE features from raw EEG data.\"\"\"\n    print(\"=\" * 80)\n    print(\"FEATURE EXTRACTION\")\n    print(\"=\" * 80)\n    \n    # Get file paths\n    all_paths = glob.glob(f\"{DATA_DIR}/sub-*/eeg/*.set\")\n    print(f\"Found {len(all_paths)} EEG files\")\n    \n    groups = {'alz': [], 'ctrl': [], 'ftd': []}\n    for fp in all_paths:\n        sid = get_subject_id(fp)\n        if sid is None:\n            continue\n        if sid <= 36:\n            groups['alz'].append(fp)\n        elif sid <= 65:\n            groups['ctrl'].append(fp)\n        else:\n            groups['ftd'].append(fp)\n    \n    print(f\"ALZ: {len(groups['alz'])}, CTRL: {len(groups['ctrl'])}, FTD: {len(groups['ftd'])}\")\n    \n    # Extract PTE features\n    print(\"\\n--- Extracting PTE features ---\")\n    for grp, paths in groups.items():\n        for fp in paths:\n            subj_id, dp, label = process_pte_subject(fp, grp)\n            out_f = os.path.join(FEATURES_DIR, f\"sub-{subj_id}_PTE_{grp}.npz\")\n            np.savez(out_f, pte_data=dp, subject_id=subj_id, label=label)\n            print(f\"  Saved {out_f}, shape={dp.shape}\")\n    \n    # Extract DE features\n    print(\"\\n--- Extracting DE features ---\")\n    for grp, paths in groups.items():\n        for fp in paths:\n            subj_id, de_vals, label = process_de_subject(fp, grp)\n            out_f = os.path.join(FEATURES_DIR, f\"sub-{subj_id}_DE_{grp}.npz\")\n            np.savez_compressed(out_f, DE_features=de_vals, subject_id=subj_id, label=label)\n            print(f\"  Saved {out_f}, shape={de_vals.shape}\")\n\ndef run_experiment(task='cn_ad'):\n    \"\"\"Run the complete experiment.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"RUNNING EXPERIMENT: {task.upper()}\")\n    print(\"=\" * 80)\n    \n    # Set seed\n    set_seed(0)\n    \n    # Configure task\n    if task == 'cn_ad':\n        selected_classes = [\"ctrl\", \"alz\"]\n        class_weights = torch.tensor([1.0, 0.7])\n        use_weights = True\n    elif task == 'cn_ftd':\n        selected_classes = [\"ctrl\", \"ftd\"]\n        class_weights = None\n        use_weights = False\n    else:\n        raise ValueError(f\"Unknown task: {task}\")\n    \n    # Model hyperparameters\n    pte_input_dim = 36  # Spatial dimension after flattening (6*6)\n    pte_hidden_dim = 512\n    pte_num_layers = 2\n    pte_num_heads = 4  # Must divide 36\n    pte_output_dim = 128\n    pte_dropout = 0.4\n    \n    psd_input_dim = 5  # Number of bands\n    psd_hidden_dim = 512\n    psd_num_layers = 2\n    psd_num_heads = 5  # Must divide 5\n    psd_output_dim = 128\n    psd_dropout = 0.4\n    \n    cross_d_model = 128\n    cross_num_heads = 8  # Must divide 128\n    \n    # Load data\n    print(\"\\n--- Loading data ---\")\n    all_folds = load_data_stratified_kfold(\n        pte_directory=FEATURES_DIR,\n        DE_directory=FEATURES_DIR,  # Both in same directory now\n        batch_size=BATCH_SIZE,\n        selected_classes=selected_classes,\n        selected_channels=SELECTED_CHANNELS,\n        n_splits=N_SPLITS,\n        n_repetitions=N_REPETITIONS,\n    )\n    \n    # Results storage\n    all_acc_final = []\n    all_f1_final = []\n    all_conf_final = []\n    global_probs_final = []\n    global_labels_final = []\n    best_thresholds_final = []\n    \n    # Device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Run experiments\n    for rep_idx, folds in enumerate(all_folds):\n        print(f\"\\n{'=' * 80}\")\n        print(f\"REPETITION {rep_idx + 1}/{len(all_folds)}\")\n        print(f\"{'=' * 80}\")\n        \n        all_acc = []\n        all_f1 = []\n        all_conf = []\n        global_probs = []\n        global_labels = []\n        best_thresholds = []\n        \n        for fold_idx, (train_loader, val_loader) in enumerate(folds, 1):\n            print(f\"\\n--- Fold {fold_idx}/{len(folds)} ---\")\n            \n            # Initialize model\n            model = FinalModel(\n                pte_input_dim=pte_input_dim,\n                pte_hidden_dim=pte_hidden_dim,\n                pte_num_layers=pte_num_layers,\n                pte_num_heads=pte_num_heads,\n                pte_output_dim=pte_output_dim,\n                pte_dropout=pte_dropout,\n                psd_input_dim=psd_input_dim,\n                psd_hidden_dim=psd_hidden_dim,\n                psd_num_layers=psd_num_layers,\n                psd_num_heads=psd_num_heads,\n                psd_output_dim=psd_output_dim,\n                psd_dropout=psd_dropout,\n                cross_d_model=cross_d_model,\n                cross_num_heads=cross_num_heads\n            )\n            model.to(device)\n            \n            # Loss and optimizer\n            if use_weights:\n                criterion_label = nn.CrossEntropyLoss(class_weights.to(device))\n            else:\n                criterion_label = nn.CrossEntropyLoss()\n            \n            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n            \n            # Train\n            print(\"Training...\")\n            label_acc_history = train_model(\n                model=model,\n                source_dataloader=train_loader,\n                target_dataloader=val_loader,\n                criterion_label=criterion_label,\n                optimizer=optimizer,\n                num_epochs=NUM_EPOCHS,\n                device=device,\n                scheduler=None,\n            )\n            print(f\"  Final training accuracy: {label_acc_history[-1]:.2f}%\")\n            \n            # Threshold tuning\n            print(\"  Tuning threshold...\")\n            thresholds_to_try = [0.2, 0.3, 0.4, 0.5]\n            best_thr = tune_threshold_on_source(\n                model=model,\n                source_dataloader=train_loader,\n                device=device,\n                thresholds=thresholds_to_try,\n                num_classes=2\n            )\n            best_thresholds.append(best_thr)\n            \n            # Test\n            print(\"  Testing...\")\n            test_loss, test_acc, test_f1, conf_mat, preds, labels, _, _ = test_model(\n                model=model,\n                test_dataloader=val_loader,\n                criterion_label=criterion_label,\n                device=device,\n                num_classes=2,\n                alz_threshold=best_thr\n            )\n            \n            print(f\"  Validation loss: {test_loss:.4f}\")\n            print(f\"  Validation accuracy: {test_acc:.2f}%\")\n            print(f\"  Validation F1: {test_f1:.4f}\")\n            \n            # Store results\n            all_acc.append(test_acc)\n            all_f1.append(test_f1)\n            all_conf.append(conf_mat)\n            global_probs.append(preds)\n            global_labels.append(labels)\n        \n        # Repetition results\n        all_acc_final.append(all_acc)\n        all_f1_final.append(all_f1)\n        all_conf_final.append(all_conf)\n        global_probs_final.append(global_probs)\n        global_labels_final.append(global_labels)\n        best_thresholds_final.append(best_thresholds)\n        \n        print(f\"\\n  Repetition {rep_idx + 1} Results:\")\n        print(f\"  Mean accuracy: {np.mean(all_acc):.2f}% ± {np.std(all_acc):.2f}%\")\n        print(f\"  Mean F1: {np.mean(all_f1):.4f} ± {np.std(all_f1):.4f}\")\n    \n    # Save results\n    final_results = {\n        \"all_acc\": all_acc_final,\n        \"all_f1\": all_f1_final,\n        \"all_conf\": all_conf_final,\n        \"global_probs\": global_probs_final,\n        \"global_labels\": global_labels_final,\n        \"best_thresholds\": best_thresholds_final\n    }\n    \n    results_file = os.path.join(RESULTS_DIR, f\"final_results_{task}_dtca.npz\")\n    np.savez(results_file, final_results=final_results)\n    print(f\"\\n✓ Saved results to {results_file}\")\n    \n    # Compute final metrics\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FINAL RESULTS\")\n    print(\"=\" * 80)\n    \n    compute_final_metrics(final_results)\n    \n    return final_results\n\ndef compute_final_metrics(final_results):\n    \"\"\"Compute and print final performance metrics.\"\"\"\n    all_runs = final_results[\"all_conf\"]\n    \n    acc_scores, precision_scores, recall_scores, f1_scores = [], [], [], []\n    \n    for run_idx, run_cms in enumerate(all_runs, start=1):\n        for fold_idx, cm in enumerate(run_cms, start=1):\n            cm = np.asarray(cm)\n            if cm.shape != (2, 2):\n                continue\n            \n            tn, fp, fn, tp = cm.ravel()\n            \n            y_true = np.array([0] * (tn + fp) + [1] * (fn + tp))\n            y_pred = np.array([0] * tn + [1] * fp + [0] * fn + [1] * tp)\n            \n            acc_scores.append(accuracy_score(y_true, y_pred))\n            precision_scores.append(precision_score(y_true, y_pred, zero_division=0))\n            recall_scores.append(recall_score(y_true, y_pred, zero_division=0))\n            f1_scores.append(f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n    \n    metrics = {\n        \"Accuracy\": (np.mean(acc_scores), np.std(acc_scores)),\n        \"Precision\": (np.mean(precision_scores), np.std(precision_scores)),\n        \"Recall\": (np.mean(recall_scores), np.std(recall_scores)),\n        \"F1-score\": (np.mean(f1_scores), np.std(f1_scores)),\n    }\n    \n    for name, (mean, std) in metrics.items():\n        print(f\"{name:12s}: {mean:.4f} ± {std:.4f}\")\n    \n    # Compute global AUC\n    gp = []\n    for i in range(len(final_results[\"global_probs\"])):\n        gp.extend(final_results[\"global_probs\"][i])\n    global_probs = np.vstack(gp)\n    \n    gl = []\n    for i in range(len(final_results[\"global_labels\"])):\n        gl.extend(final_results[\"global_labels\"][i])\n    global_labels = np.hstack(gl)\n    \n    global_auc = roc_auc_score(global_labels, global_probs[:, 1])\n    print(f\"\\nGlobal AUC: {global_auc:.4f}\")\n    \n    # Plot ROC curve\n    fpr, tpr, _ = roc_curve(global_labels, global_probs[:, 1])\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"AUC = {global_auc:.4f}\")\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(alpha=0.3)\n    plt.savefig(os.path.join(RESULTS_DIR, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"✓ Saved ROC curve to {RESULTS_DIR}/roc_curve.png\")\n\n# ═══════════════════════════════════════════════════════════════════════════\n# MAIN EXECUTION\n# ═══════════════════════════════════════════════════════════════════════════\n\nif __name__ == \"__main__\":\n    print(\"=\" * 80)\n    print(\"DTCA-NET: DUAL-TRANSFORMER CROSS ATTENTION NETWORK\")\n    print(\"EEG-based Alzheimer's and Frontotemporal Dementia Detection\")\n    print(\"=\" * 80)\n    \n    # Step 1: Extract features (comment out if already extracted)\n    print(\"\\n[1/3] Extracting features from raw EEG data...\")\n    extract_features()\n    \n    # Step 2: Run CN vs AD experiment\n    print(\"\\n[2/3] Running CN vs AD experiment...\")\n    results_cn_ad = run_experiment(task='cn_ad')\n    \n    # Step 3: Run CN vs FTD experiment\n    print(\"\\n[3/3] Running CN vs FTD experiment...\")\n    results_cn_ftd = run_experiment(task='cn_ftd')\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"EXPERIMENT COMPLETED SUCCESSFULLY\")\n    print(\"=\" * 80)\n    print(f\"Results saved in: {RESULTS_DIR}\")\n    print(\"=\" * 80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T12:24:37.812767Z","iopub.execute_input":"2025-11-10T12:24:37.813023Z","iopub.status.idle":"2025-11-10T18:41:52.761552Z","shell.execute_reply.started":"2025-11-10T12:24:37.812997Z","shell.execute_reply":"2025-11-10T18:41:52.760924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add this code at the end of your notebook\nimport shutil\nimport os\n\n# Create a zip file of all results\noutput_dir = '/kaggle/working'\nzip_filename = '/kaggle/working/all_results'\n\nshutil.make_archive(zip_filename, 'zip', output_dir)\nprint(f\"Created: {zip_filename}.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T18:48:04.550186Z","iopub.execute_input":"2025-11-10T18:48:04.550474Z","iopub.status.idle":"2025-11-10T18:48:07.601320Z","shell.execute_reply.started":"2025-11-10T18:48:04.550453Z","shell.execute_reply":"2025-11-10T18:48:07.600484Z"}},"outputs":[],"execution_count":null}]}